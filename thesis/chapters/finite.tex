\chapter{El caso finito}
\noindent
Debido a que $\vec{p} > \vec{0}$, resulta valioso mencionar que el problema
(\ref{theory:formulation}) es una instancia particular del famoso Problema de la Mochila
\begin{subequations}
	\label{knapsack-formulation}
	\begin{align}
		\max_{\vec{x} \in \Z^n} \quad
			& \vec{u}^T\vec{x}, \\
		\text{s.a.} \quad
			& \vec{w}^T\vec{x} \leq c, \\
			& \vec{x} \geq \vec{0},
	\end{align}
\end{subequations}
donde los vectores positivos $\vec{u}, \vec{w} \in \Z^n$ son conocidos como vector de útiles y
vector de pesos, respectivamente. Puesto que no acotamos $\vec{x}$, el problema recibe el nombre de
Problema de la Mochila no Acotado. Pero también como $\vec{u} = \vec{w}$, el problema
también puede ser considerado como un Problema de la Suma de Conjuntos no Acotado. En nuestro análisis
de resultados comparamos los tiempos de terminación de nuestro algoritmo con los de Ramificación y
Acotamiento, \texttt{MTU2} (\cite{martello}), y una formulación alternativa de programación dinámica.

De acuerdo al Teorema \ref{theory:th:feasibility}, el número de puntos factibles sobre la
$\eta$-ésima capa entera es finito y, por lo tanto, puede ser cero. No obstante, al igual que en la
sección anterior, somos capaces de caracterizar todos los puntos enteros que se encuentran en
cualquier capa entera. Consecuentemente, si determinamos que no hay ningún punto factible en la
$\eta$-ésima capa entera, descendemos a la $(\eta -1)$-ésima capa entera y realizamos el mismo
análisis.

Además, observemos que en realidad es suficiente con descender hasta la 0-ésima capa entera, pues
los puntos enteros sobre capas menores tienen utilidades negativas. De acuerdo al Teorema
\ref{theory:th:feasibility}, estos no pueden ser factibles. Concluimos entonces que basta con
analizar las capas enteras con parámetros $k \in \lbrace \eta, \eta - 1, \ldots, 0 \rbrace$ y
terminamos una vez que encontremos un punto no negativo.

Así pues, sea $k \in \lbrace \eta, \eta - 1, \ldots, 0 \rbrace$. Al igual que en el caso anterior,
deseamos resolver la ecuación lineal diofantina
\begin{equation*}
	\vec{q}^T\vec{x} = q_1x_1 + q_2x_2 + \cdots + q_nx_n = k.
\end{equation*}
Implementamos la misma estrategia para plantear una formulación dinámica,
\begin{equation*}
	\frac{q_1}{g_1}x_1 + g_2\omega_2 = \omega_1.
\end{equation*}
No obstante, en este caso podemos interpretar $\omega_2$ de tal manera que obtengamos más
información. Así como $\omega_1 \coloneq k$  es el presupuesto disponible en un inicio, $\omega_2$
es el presupuesto disponible después de utilizar parte de él para adquirir $x_1 \geq 0$ unidades.
Por lo tanto, es posible agregar la restricción $\omega_2 \geq 0$. Similarmente, en el $i$-ésimo
paso de la formulación dinámica, somos capaces de agregar la restricción de que el presupuesto
restante $\omega_{i + 1}$ sea no negativo. Combinando esto con la no negatividad de $x_i$, obtenemos
de (\ref{phase-1:eq:recursive}),
\begin{equation}
	\label{phase-1:finite:eq:param-bounds}
	\left\lceil -\frac{\omega_ix_i'}{g_{i+1}} \right\rceil
	\leq
	t_i
	\leq
	\left\lfloor \frac{\omega_i\omega_{i+1}'}{q_i} \prod_{j=1}^{i}g_j \right\rceil.
\end{equation}
para todo $i \in \lbrace 1, \ldots, n - 2\rbrace$. Después, como $0 < q_{n - 1}, q_n$, se sigue de
(\ref{phase-1:eq:lastsol}),
\begin{equation}
	\label{phase-1:finite:eq:param-bounds-last}
	\left\lceil -\frac{\omega_{n-1}x_{n-1}'}{q_n} \cdot \prod_{j=1}^{n-2}g_j \right\rceil
	\leq
	t_{n - 1}
	\leq
	\left\lfloor \frac{\omega_{n-1}x_{n}'}{q_{n-1}} \cdot \prod_{j=1}^{n-2}g_j \right\rfloor.
\end{equation}

De igual manera que el caso infinito, hacemos \textit{backtracking} en caso de encontrarnos con que
$t_i \in \Z$ no puede satisfacer (\ref{phase-1:finite:eq:param-bounds}) si $i \in \lbrace 1, \ldots,
n - 2\rbrace$, o si $t_{n - 2} \in \Z$ no puede satisfacer
(\ref{phase-1:finite:eq:param-bounds-last}). En este caso, puede ser que en cualquier nivel $t_i$ no
se satisfaga la desigualdad y por lo tanto que necesitemos cambiar uno de $t_1, \ldots, t_{i -
1}$. Ciertamente, la elección más simple es realizar el cambio $t_{i - 1} \leftarrow t_{i - 1} \pm
1$ siempre y cuando continúe satisfaciendo sus cotas correspondientes.

El número de elecciones $t_1, \ldots, t_{n - 1} \in \Z$ es finito para la $k$-ésima capa entera.
Decidimos, finalmente, descender a la $(k - 1)$-capa entera y repetir el proceso si en ninguna de esas
elecciones se satisfacen ambas (\ref{phase-1:finite:eq:param-bounds}) y
(\ref{phase-1:finite:eq:param-bounds-last}). Evidentemente, $\vec{0} \in \Z^n$ es factible y se
encuentra en la 0-ésima capa, por lo que este proceso está asegurado en terminar si es que el
problema es factible, lo cual supusimos desde un inicio.

Con respecto a la complejidad algorítmica de este procedimiento podemos decir lo siguiente.
Supongamos que modificamos el algoritmo para que encuentre todas las soluciones. Definamos
\begin{equation}
	\label{phase-1:def:feasible-layer}
	P_k \coloneq H_{\vec{q}, k\norm{\vec{q}}^{-2}} \cap \Z_{\geq \vec{0}}^n
	=
	\lbrace \vec{x} \in \Z^n \vcentcolon \vec{q}^T\vec{x} = k, \vec{x} \geq \vec{0}
	\rbrace,
\end{equation}
y sea $T(n)$ el tiempo requerido para encontrar todos los puntos en $P_k$ o determinar que este
conjunto es vacío\footnote{Estamos suponiendo implícitamente que el tiempo no depende del lado
	derecho $k$, por lo que depende exclusivamente de la dimensión del politopo. Es la creencia del
	autor que en realidad el tiempo es linealmente decreciente en $k$ puesto que la probabilidad de
	que haya puntos enteros en $P_k$ es mayor a medida que $k$ aumenta. Si bien los resultados
	numéricos apuntan a que esta hipótesis es cierta, el autor prefirió decir que el tiempo es
constante a falta de un mejor argumento teórico.}. Es razonable suponer que $T(n)$ es exponencial en
$n$. En efecto, cada par $(x_i, \omega_{i + 1})$ genera un intervalo de factibilidad $[t_i^{\min},
t_i^{\max}]$. Este intervalo ciertamente depende de las elecciones previas de $t_1, \ldots, t_{i -
1}$. Para encontrar todos los puntos en $P_k$, el algoritmo recorre todas las posibilidades:
\begin{equation}
	\label{phase-1:complexity:bounds}
	\prod_{i=1}^{\tau_1} \min_{t_1, \ldots, t_{i-1}} \lbrace t_i^{\max} - t_i^{\min} \rbrace
	\leq T(n) \leq
	\prod_{i=1}^{\tau_2} \max_{t_1, \ldots, t_{i-1}} \lbrace t_i^{\max} - t_i^{\min} \rbrace,
\end{equation}
donde $1 \leq \tau_1 \leq n$ es el entero más grande que asegura que  $\min_{t_1, \ldots, t_{i -
1}}\lbrace t_i^{\max} - t_i^{\min} \rbrace$ sea positivo para todo $i \in \lbrace 1, \ldots, \tau_1
\rbrace$. Definimos $\tau_2$ de manera análoga. Se cumple que $\tau_1 \leq \tau_2$. Sean
$\ell_{\min}, \ell_{\max}$ las longitudes del intervalo de factibilidad más pequeño y del más grande
en todos los niveles, respectivamente. Es decir, definimos
\begin{align}
	\ell_{\min} &\coloneq \min_{1 \leq i \leq \tau_1} \left\lbrace \min_{t_1, \ldots, t_{i - 1}} \lbrace
	t_i^{\max} - t_i^{\min} \rbrace \right\rbrace,
	\\
	\ell_{\max} &\coloneq \max_{1 \leq i \leq \tau_2} \left\lbrace \max_{t_1, \ldots, t_{i - 1}} \lbrace
	t_i^{\max} - t_i^{\max} \rbrace \right\rbrace.
\end{align}
Si $P_k$ es vacío, se sigue que no existe ningún intervalo factible en el nivel $n$, lo que implica
que $\tau_2 < n$. En caso contrario, el algoritmo recorre hasta el último nivel, por lo que $\tau_1
= \tau_2 = n$. De (\ref{phase-1:complexity:bounds}), obtenemos
\begin{equation}
	\ell_{\min}^{n} \leq T(n) \leq \ell_{\max}^{n}.
\end{equation}
En el peor de los casos, nuestro algoritmo recorre todas las capas enteras. Se sigue que
\begin{equation}
	\label{phase-1:time}
	\text{Tiempo de ejecución}
	= \mathcal{O} \left(\sum_{k=1}^{\eta} T(n) \right)
	= \mathcal{O}(\eta \cdot T(n))
	= \mathcal{O}(\eta \cdot c^{n}),
\end{equation}
para alguna $c > 1$.

Ahora bien, este razonamiento aplica a la modificación del algoritmo en donde decidimos buscar todas
las soluciones posibles. En realidad solo nos interesa encontrar un punto óptimo, por lo que podemos
concluir que una cota superior para la complejidad de nuestro algoritmo es (\ref{phase-1:time}).
Concluimos esta sección diciendo haremos uso del mismo razonamiento para determinar la complejidad
algorítmica de nuestro método en la segunda fase de su construcción. Finalmente, observemos también
que, para problemas del tipo (\ref{theory:formulation}), la solución siempre se encuentra
razonablemente cerca de la frontera presupuestaria $\vec{p}^T\vec{x} = u$, así que a excepción de
casos degenerados, nunca recorre nuestro algoritmo todas las capas enteras.
