\chapter{El caso finito}
\noindent
Debido a que $\vec{p} > \vec{0}$, resulta valioso mencionar que el problema
(\ref{theory:formulation}) es una instancia particular del famoso Problema de la Mochila
\begin{subequations}
	\label{knapsack-formulation}
	\begin{align}
		\max_{\vec{x} \in \Z^n} \quad
			& \vec{u}^T\vec{x}, \\
		\text{s.a.} \quad
			& \vec{w}^T\vec{x} \leq c, \\
			& \vec{x} \geq \vec{0},
	\end{align}
\end{subequations}
donde los vectores positivos $\vec{u}, \vec{w} \in \Z^n$ son conocidos como vector de útiles y
vector de pesos, respectivamente. Puesto que no acotamos $\vec{x}$, el problema recibe el nombre de
Problema de la Mochila no Acotado. Pero también como $\vec{u} = \vec{w}$, el problema
también puede ser considerado como un Problema de la Suma de Conjuntos no Acotado. En nuestro análisis
de resultados comparamos los tiempos de terminación de nuestro algoritmo con los de Ramificación y
Acotamiento, \texttt{MTU2} (\cite{martello}), y una formulación alternativa de programación dinámica.

De acuerdo al Teorema \ref{theory:th:feasibility}, el número de puntos factibles sobre la
$\eta$-ésima capa entera es finito y, por lo tanto, puede ser cero. No obstante, al igual que en la
sección anterior, somos capaces de caracterizar todos los puntos enteros que se encuentran en
cualquier capa entera. Consecuentemente, si determinamos que no hay ningún punto factible en la
$\eta$-ésima capa entera, descendemos a la $(\eta -1)$-ésima capa entera y realizamos el mismo
análisis.

\begin{lemma}
	Sea
	\begin{equation}
		\label{eq:last-index}
		i^* \coloneq \argmax \left\lbrace \frac{1}{\vec{q}_1}, \ldots, \frac{1}{\vec{q}_n} \right\rbrace,
	\end{equation}
	y definamos
	\begin{equation}
		\label{eq:tau}
		\tau \coloneq \left\lfloor \left\lfloor \frac{u}{\vec{q}_{i^*}} \right\rfloor
			\frac{\vec{q}_{i^*}}{m} \right\rfloor.
	\end{equation}
	Entonces la solución del problema (\ref{theory:formulation}) se encuentra en una capa entera
	parametrizada por $k \in \lbrace \eta, \eta - 1, \ldots, \tau \rbrace$.
\end{lemma}
\begin{proof}
	Consideremos el vector
	\begin{equation*}
		\vec{v} \coloneq \left\lfloor \frac{u}{\vec{q}_{i^*}} \right\rfloor \vec{e}_{i^*},
	\end{equation*}
	y observemos que $\vec{v} \geq \vec{0}$, pues $\vec{q} > \vec{0}$ y supusimos que el problema
	(\ref{theory:formulation}) es factible, por lo que $u \geq 0$. Así también, tenemos
	\begin{equation*}
		\vec{q}^T\vec{v} = \left\lfloor \frac{u}{\vec{q}_{i^*}} \right\rfloor \vec{q}_{i^*}
		\leq \frac{u}{\vec{q}_{i^*}}\vec{q}_{i^*} = u,
	\end{equation*}
	y entonces $\vec{v}$ es factible. De aquí se sigue que este vector provee una cota inferior para
	el problema (\ref{theory:formulation}). Así pues, todo vector $\vec{x}$ candidato a ser el
	óptimo del problema satisface
	\begin{equation*}
		\vec{q}^T\vec{x} = \frac{\vec{p}^T\vec{x}}{m} \geq \left\lfloor \frac{u}{\vec{q}_{i^*}}
		\right\rfloor \frac{\vec{q}_{i^*}}{m}.
	\end{equation*}
	Nos interesa calcular el número entero $\tau$ más pequeño tal que todo punto sobre la capa
	entera $H_{\vec{q}, k\norm{\vec{q}}^{-2}}$ con $k \in \lbrace \tau, \tau + 1, \ldots \rbrace$
	satisfaga esta desigualdad. Del Lema \ref{phase-1:lemma:layer}, toda $k$ debe satisfacer
	\begin{equation*}
		k\norm{\vec{q}}^{-2} = \frac{\vec{q}^T\vec{x}}{\norm{\vec{q}}^2} \geq
		\left\lfloor \frac{u}{\vec{q}_{i^*}} \right\rfloor \frac{\vec{q}_{i^*}}{m}
		\frac{1}{\norm{\vec{q}}^2},
	\end{equation*}
	y por lo tanto
	\begin{equation*}
		\tau =
		\left\lfloor \left\lfloor \frac{u}{\vec{q}_{i^*}} \right\rfloor \frac{\vec{q}_{i^*}}{m}
			\right\rfloor.
	\end{equation*}
	Finalmente, recordemos que $\eta$ es la primera capa en satisfacer la restricción presupuestaria.
	Por lo tanto, el óptimo del problema (\ref{theory:formulation}) se encuentra en una capa
	parametrizada por $k \in \lbrace \eta, \eta - 1, \ldots, \tau \rbrace$.
\end{proof}

\begin{observation}
	Siempre se cumple que $\tau \leq \eta$. En efecto,
	\begin{equation*}
		\left\lfloor \frac{u}{\vec{q}_{i^*}} \right\rfloor \vec{q}_{i^*}
		\leq \frac{u}{\vec{q}_{i^*}} \vec{q}_{i^*} = u,
	\end{equation*}
	como $m > 0$, tenemos
	\begin{equation*}
		\left\lfloor \frac{u}{\vec{q}_{i^*}} \right\rfloor \frac{\vec{q}_{i^*}}{m}
		\leq \frac{u}{m}.
	\end{equation*}
	Aplicando la función piso a ambos lados de la desigualdad encontramos que $\tau \leq \eta$.
\end{observation}
Sea $k \in \lbrace \eta, \eta - 1, \ldots, \tau \rbrace$. Sabemos de la sección de Fundamentos en el
primer capítulo que deseamos resolver la ecuación lineal diofantina
\begin{equation*}
	\vec{q}^T\vec{x} = \vec{q}_1\vec{x}_1 + \vec{q}_2\vec{x}_2 + \cdots + \vec{q}_n\vec{x}_n = k.
\end{equation*}
Implementamos la misma estrategia para plantear una formulación recursiva,
\begin{equation*}
	\frac{q_1}{g_1}\vec{x}_1 + g_2\omega_2 = \omega_1.
\end{equation*}
No obstante, en este caso podemos interpretar $\omega_2$ de tal manera que obtengamos más
información. Así como $\omega_1 \coloneq k$  es el presupuesto disponible en un inicio, $\omega_2$
es el presupuesto disponible después de utilizar parte de él para adquirir $\vec{x}_1 \geq 0$ unidades.
Por lo tanto, es posible agregar la restricción $\omega_2 \geq 0$. Similarmente, en el $i$-ésimo
paso de la formulación recursiva, somos capaces de agregar la restricción de que el presupuesto
restante $\omega_{i + 1}$ sea no negativo. Combinando esto con la no negatividad de $\vec{x}_i$, obtenemos
de (\ref{eq:recurrence}),
\begin{equation}
	\label{phase-1:finite:eq:param-bounds}
	\left\lceil -\frac{\omega_ix_i'}{g_{i+1}} \right\rceil
	\leq
	\vec{t}_i
	\leq
	\left\lfloor \frac{\omega_i\omega_{i+1}'}{\vec{q}_i} \prod_{j=1}^{i}g_j \right\rceil.
\end{equation}
para todo $i \in \lbrace 1, \ldots, n - 2\rbrace$. Después, como $0 < \vec{q}_{n - 1}, \vec{q}_n$, se sigue de
(\ref{eq:last-solution}),
\begin{equation}
	\label{phase-1:finite:eq:param-bounds-last}
	\left\lceil -\frac{\omega_{n-1}x_{n-1}'}{\vec{q}_n} \cdot \prod_{j=1}^{n-2}g_j \right\rceil
	\leq
	\vec{t}_{n - 1}
	\leq
	\left\lfloor \frac{\omega_{n-1}x_{n}'}{\vec{q}_{n-1}} \cdot \prod_{j=1}^{n-2}g_j \right\rfloor.
\end{equation}

Consecuentemente, el número de elecciones que podemos hacer para $\vec{t} \in \Z^{n-1}$ es finito.
Observemos que una elección de $\vec{t}_i$ modifica $\omega_{i+1}$ y por lo tanto también afecta el
intervalo de factibilidad de $\vec{t}_{i+1}$. Siguiendo con este razonamiento, encontramos que una
elección de $\vec{t}_i$ afecta los intervalos de factibilidad de $\vec{t}_{i+1}, \ldots,
\vec{t}_{n-1}$.

Es decir, a pesar de que el óptimo se encuentre sobre la capa entera $k$ que estamos analizando, la
elección de los primeros parámetros que realicemos puede afectar el tiempo de terminación de nuestro
algoritmo. Hay dos extremos en las posibles estrategias que podemos adoptar para realizar estas
elecciones. Para visualizarlo, tenemos que nuestro presupuesto actual $\omega_{i}$ determina el
siguiente presupuesto a partir de
\begin{equation*}
	\begin{cases}
		\vec{x}_i = \omega_ix_i' + g_{i+1}\vec{t}_i, \\
		\omega_{i+1} = \omega_i\omega_{i+1}' - \frac{\vec{q}_i}{\prod_{j=1}^{i}g_j}\vec{t}_i,
	\end{cases}
\end{equation*}
donde la primera ecuación indica cuántos elementos de $\vec{x}_i$ decidimos adquirir a partir del
presupuesto actual $\omega_i$.

El primer extremo está en buscar agotar todo nuestro presupuesto disponible en las primeras
elecciones de $\vec{x}_1, \vec{x}_2, \ldots, \vec{x}_i$. Es decir, adquirimos la mayor cantidad que
podamos de los primeros productos. Bajo esta perspectiva, es razonable imponer un orden en $\vec{q}$
de manera que
\begin{equation*}
	\vec{q}_1 \geq \vec{q}_2 \geq \cdots \geq \vec{q}_n,
\end{equation*}
de manera que adquirimos primero los artículos más caros. En este caso diremos que $\vec{q}$ está en
orden descendente. Si adoptamos esta estrategia es porque suponemos que el óptimo se concentra en
una vecindad de los primeros $i$ artículos. Es decir, si tenemos la creencia de que $\vec{q}_{i +
1}, \ldots, \vec{x}_n$ pueden ser aproximadamente cero.

% TODO: es mejor argumentar esto en la sección de análisis de resultados.
% De ser este el caso, entonces es razonable suponer que los tiempos de terminación de esta búsqueda
% son similares a los de Ramificación y Acotamiento. 

El segundo extremo es esencialmente lo opuesto. Esto no quiere decir que ahora ordenamos $\vec{q}$
de manera ascendente y escogemos las primera $\vec{t}_i$ lo más pequeñas posible\footnote{Si
	hiciéramos esto es porque creemos que $\vec{x}_1, \ldots, \vec{x}_i$ son aproximadamente cero,
	pero entonces podemos permutar estas entradas de manera que se encuentren hasta el final y
emplear la primera estrategia.}. Consiste en escoger $\vec{t}_i$ de manera que se encuentre en el
punto medio de sus cotas inferiores y superiores. Es decir, creemos que el óptimo se encuentra en
una vecindad del centro de masa de la $k$-ésima capa entera.

Observemos que, independientemente del caso, si una capa entera no contiene puntos factibles, entonces
ambas estrategias agotan hacen todas las elecciones posibles de $\vec{t}_1, \ldots, \vec{t}_{n-1}$.
Por lo tanto, los tiempos de terminación de ambas estrategias son iguales para capas enteras que no
contienen puntos enteros no negativos. La segunda estrategia, no obstante, es candidata ideal para
realizar una búsqueda binaria. Discutimos más sobre esto último en la sección de análisis de
resultados.

Con respecto a la complejidad algorítmica de este procedimiento podemos decir lo siguiente.
Supongamos que modificamos el algoritmo para que encuentre todas las soluciones. Definamos
\begin{equation}
	\label{phase-1:def:feasible-layer}
	P_k \coloneq H_{\vec{q}, k\norm{\vec{q}}^{-2}} \cap \Z_{\geq \vec{0}}^n
	=
	\lbrace \vec{x} \in \Z^n \vcentcolon \vec{q}^T\vec{x} = k, \vec{x} \geq \vec{0}
	\rbrace,
\end{equation}
y sea $T(n)$ el tiempo requerido para encontrar todos los puntos en $P_k$ o determinar que este
conjunto es vacío. Es razonable suponer que $T(n)$ es exponencial en $n$. En efecto, cada par $(x_i,
\omega_{i + 1})$ genera un intervalo de factibilidad $[t_i^{\min}, t_i^{\max}]$. Este intervalo
ciertamente depende de las elecciones previas de $t_1, \ldots, t_{i - 1}$. Para encontrar todos los
puntos en $P_k$, el algoritmo recorre todas las posibilidades:
\begin{equation}
	\label{phase-1:complexity:bounds}
	\prod_{i=1}^{\kappa_1} \min_{t_1, \ldots, t_{i-1}} \lbrace t_i^{\max} - t_i^{\min} \rbrace
	\leq T(n) \leq
	\prod_{i=1}^{\kappa_2} \max_{t_1, \ldots, t_{i-1}} \lbrace t_i^{\max} - t_i^{\min} \rbrace,
\end{equation}
donde $1 \leq \kappa_1 \leq n$ es el entero más grande que asegura que  $\min_{t_1, \ldots, t_{i -
1}}\lbrace t_i^{\max} - t_i^{\min} \rbrace$ sea positivo para todo $i \in \lbrace 1, \ldots, \kappa_1
\rbrace$. Definimos $\kappa_2$ de manera análoga. Se cumple que $\kappa_1 \leq \kappa_2$. Sean
$\ell_{\min}, \ell_{\max}$ las longitudes del intervalo de factibilidad más pequeño y del más grande
en todos los niveles, respectivamente. Es decir, definimos
\begin{align}
	\ell_{\min} &\coloneq \min_{1 \leq i \leq \kappa_1} \left\lbrace \min_{t_1, \ldots, t_{i - 1}} \lbrace
	t_i^{\max} - t_i^{\min} \rbrace \right\rbrace,
	\\
	\ell_{\max} &\coloneq \max_{1 \leq i \leq \kappa_2} \left\lbrace \max_{t_1, \ldots, t_{i - 1}} \lbrace
	t_i^{\max} - t_i^{\max} \rbrace \right\rbrace.
\end{align}
Si $P_k$ es vacío, se sigue que no existe ningún intervalo factible en el nivel $n$, lo que implica
que $\kappa_2 < n$. En caso contrario, el algoritmo recorre hasta el último nivel, por lo que $\kappa_1
= \kappa_2 = n$. De (\ref{phase-1:complexity:bounds}), obtenemos
\begin{equation}
	\ell_{\min}^{n} \leq T(n) \leq \ell_{\max}^{n}.
\end{equation}
En el peor de los casos, nuestro algoritmo recorre todas las capas enteras parametrizadas por
$\lbrace \eta, \eta - 1, \ldots, \tau\rbrace$. Se sigue que
\begin{align}
	\label{phase-1:time}
	\text{Tiempo de ejecución}
	= \mathcal{O}((\eta - \tau) \cdot T(n))
	= \mathcal{O}(c^{n}),
\end{align}
para alguna $c > 1$.

Ahora bien, este razonamiento aplica a la modificación del algoritmo en donde decidimos buscar todas
las soluciones posibles. En realidad solo nos interesa encontrar un punto óptimo, por lo que podemos
concluir que una cota superior para la complejidad de nuestro algoritmo es (\ref{phase-1:time}).
Asímismo, en la práctica encontramos que la diferencia $\eta - \tau$ es crucial para determinar
cuántas capas enteras recorre nuestro algoritmo en el peor de los casos. Por lo tanto, un estudio
sobre la distribución de esta diferencia resulta ser interesante.
\begin{lemma}
	\label{lemma:layer-dist}
	Sean $m, q$ enteros distintos de cero. Entonces la función $\Delta \colon \R \to \R$ dada por
	\begin{align*}
		\Delta(x) &\coloneq \left\lfloor \frac{x}{m} \right\rfloor - \left\lfloor \left\lfloor
		\frac{x}{q} \right\rfloor \frac{q}{m} \right\rfloor,
	\end{align*}
	es periódica con periodo $\lcm{q, m}$.
\end{lemma}
\begin{proof}
	Tenemos
	\begin{align*}
		\Delta(x + \lcm{q, m})
		&= \left\lfloor \frac{x}{m} + \frac{\lcm{q, m}}{m} \right\rfloor
		- \left\lfloor \left\lfloor \frac{x}{q} + \frac{\lcm{q,m}}{q} \right\rfloor \frac{q}{m}
			\right\rfloor,
	\end{align*}
	pero $q, m \mid \lcm{q, m}$, por lo que $\lcm{q,m}/m$ y $\lcm{q,m}/q$ son enteros. Por las
	propiedades de la función piso obtenemos los que queremos demostrar:
	\begin{align*}
		\Delta(x + \lcm{q,m})
		&=
		\left\lfloor \frac{x}{m} \right\rfloor + \frac{\lcm{q,m}}{m}
		- \left\lfloor \left\lfloor \frac{x}{q} \right\rfloor\frac{q}{m} + 
			\frac{\lcm{q,m}}{q}\cdot\frac{q}{m} \right\rfloor \\
		&= 
		\left\lfloor \frac{x}{m} \right\rfloor + \frac{\lcm{q,m}}{m}
		- \left\lfloor \left\lfloor \frac{x}{q} \right\rfloor\frac{q}{m}\right\rfloor
		- \frac{\lcm{q,m}}{m} \\
		&= 
		\left\lfloor \frac{x}{m} \right\rfloor
		- \left\lfloor \left\lfloor \frac{x}{q} \right\rfloor\frac{q}{m}\right\rfloor \\
		&= \Delta(x).
	\end{align*}
\end{proof}
\begin{definition}
	Sea $\vec{p} \in \R^n$ un vector esencialmente entero y sea $\vec{q} \in \Z^n$ su múltiplo
	coprimo. Consideremos los parámetros $\eta$ y $\tau$ (c.f. \ref{phase-1:lemma:eta},
	\ref{eq:tau}) como funciones del presupuesto $u$. Entonces decimos que la función $\Delta^*
	\colon \R \to \R$ dada por
	\begin{equation}
		\label{eq:dist-layers}
		\Delta^*(u) \coloneq \eta(u) - \tau(u)
	\end{equation}
	denota el número de capas enteras a revisar dado el presupuesto $u$.
\end{definition}

Si queremos aplicar el Lema \ref{lemma:layer-dist}, debemos reducir nuestra atención a vectores
$\vec{p} \in \Z^n$ distintos de cero. Esto se debe a que debemos asegurar que el múltiplo $m \neq 0$
sea entero\footnote{Es la creencia del autor que este resultado se puede generalizar para múltiplos
$m$ racionales, mas esto no agrega demasiado valor en lo que sigue de la tesis.}. Independientemente
del comportamiento periódico de $\Delta*$, observemos que depende en gran medida del múltiplo $m$.
Esto último implica que el número de capas enteras a revisar depende del número de cifras decimales
usadas para especificar $\vec{p}$.

\begin{example}
	Si tenemos $\vec{p} \coloneq (9.6, 7.2, 5.6)^T$, entonces $m = 0.8$ y por lo tanto el número de
	capas a revisar dado $u \coloneq 119$ es $\Delta^*(u) = 14$. En cambio, si tenemos $\vec{p} \coloneq
	(9.60, 7.28, 5.68)^T$, obtenemos $m = 0.08$, por lo que el número de capas a revisar dado $u$ es
	$\Delta^*(u) = 1499$. Es decir, si usamos una cifra decimal más, entonces $\Delta^*(u)$ se
	multiplica por 100, aproximadamente.
\end{example}

% TODO: agregar imágenes que muestren el número de capas enteras dado el presupuesto. Un buen
% parámetro es m = 8, q = 12. Igual mostrar con varios decimales.
Observaremos en el análisis de resultados que el número de capas enteras que nuestro algoritmo
revisa en realidad disminuye a medida que aumenta el presupuesto $u$. Demostraremos a continuación
que para $u$ suficientemente grande, la solución al problema (\ref{theory:formulation}) se encuentra
en la $\eta$-ésima capa entera. Este resultado es análogo al caso infinito del Teorema
(\ref{theory:th:feasibility}). No obstante, necesitamos primero de un par de Definiciones y Lemas
preliminares.

% TODO: especificar hacia dónde se dirige lo que estamos haciendo

Sea $H_{\vec{q}, k\norm{\vec{q}}^{-2}}$ una capa entera. Entonces definimos la bola cerrada sobre
esta capa entera con radio $r \in \R_{>0}$ y centro $\vec{x} \in H_{\vec{q}, k\norm{\vec{q}}^{-2}}$ como
\begin{equation}
	\label{eq:k-ball}
	B_r^{(k)}(\vec{x}) \coloneq \lbrace \vec{y} \in \R^n \colon \norm{\vec{y} - \vec{x}} \leq r
	\rbrace \cap H_{\vec{q}, k \norm{\vec{q}}^{-2}}.
\end{equation}
% TODO: mostrar una imagen con una bola.
\begin{lemma}
	\label{lemma:ball-cover}
	Existe $r \in \R_{>0}$ tal que la familia de bolas
	\begin{equation*}
		\left\lbrace B_r^{(k)}(\vec{x}) \colon \vec{x} \in H_{\vec{q}, k\norm{\vec{q}}^{-2}} \cap
			\Z^n \right\rbrace
	\end{equation*}
	es una cubierta de $H_{\vec{q}, k\norm{\vec{q}}^{-2}}$.
\end{lemma}
\begin{proof}
	Recordemos del Teorema (\ref{th:lattice}) que $\vec{x} \in H_{\vec{q}, k\norm{\vec{q}}^{-2}}
	\cap \Z^n$ si y solo si $\vec{x} = k\vec{\omega} + M\vec{t}$ para algún $\vec{t} \in \Z^{n-1}$.
	Así, tenemos
	\begin{equation*}
		\left\lbrace B_r^{(k)}(\vec{x}) \colon \vec{x} \in H_{\vec{q}, k\norm{\vec{q}}^{-2}} \cap
			\Z^n \right\rbrace
			=
		\left\lbrace B_r^{(k)}(k\vec{\omega} + M\vec{t}) \colon \vec{t} \in \Z^{n-1} \right\rbrace.
	\end{equation*}
	Por un lado, sabemos que $B_r^{(k)}(k\vec{\omega} + M\vec{t}) \subseteq H_{\vec{q}, k\norm{\vec{q}}^{-2}}$ para
	todo punto entero $\vec{t} \in \Z^{n-1}$. Luego, para cualquier $r \in \R_{>0}$ tenemos
	\begin{equation}
		\label{eq:ball-cover:1}
		\bigcup_{\vec{t} \in \Z^{n-1}}B_r^{(k)}(k\vec{\omega} + M\vec{t}) \subseteq
		H_{\vec{q}, k\norm{\vec{q}}^{-2}}.
	\end{equation}
	Ahora bien, sea $\vec{y}$ un punto sobre la $k$-ésima capa entera. Como los renglones de $M$ son
	linealmente independientes, existe $\vec{t} \in \R^{n-1}$ tal que
	\begin{equation*}
		\vec{y} = k\vec{\omega} + M\vec{t}.
	\end{equation*}
	Sea $\lfloor \vec{t} \rceil \in \Z^{n-1}$ el vector resultante de redondear cada entrada de
	$\vec{t}$ al entero más cercano. Luego, $\vec{t} = \lfloor \vec{t} \rfloor + \vec{\delta}$,
	donde $\vec{\delta} \in \R^{n-1}$ satisface $\norm{\vec{\delta}}_{\infty} \leq 0.5$. Definamos
	\begin{equation*}
		\vec{x} \coloneq k\vec{\omega} + M\lfloor \vec{t} \rceil \in \Z^{n-1},
	\end{equation*}
	de donde se sigue que
	\begin{align*}
		\norm{\vec{y} - \vec{x}}_2^{2}
		&= \norm{M\vec{\delta}}_{2}^{2} \\
		&\leq \sum_{i=1}^{n-1}|\vec{\delta}_i|^2 \norm{M\vec{e}_i}_2^{2} \\
		&\leq \frac{1}{4}\sum_{i=1}^{n-1} \norm{M\vec{e}_i}_2^{2} \\
		&= \frac{1}{4}\norm{M}_F^2,
	\end{align*}
	donde $\norm{M}_F$ denota la norma Frobenius de $M$. Por lo tanto, si definimos
	\begin{equation}
		\label{eq:radius}
		r \coloneq \frac{1}{2}\norm{M}_F,
	\end{equation}
	entonces para todo $\vec{y} \in \R^n$ sobre la $k$-ésima capa entera, existe $\vec{x} \in \Z^n$
	sobre esa misma capa entera tal que $\vec{y} \in B_r^{(k)}(\vec{x})$. Por lo tanto,
	\begin{equation}
		\label{eq:ball-cover:2}
		H_{\vec{q}, k\norm{\vec{q}}^{-2}} \subseteq
		\bigcup_{\vec{t} \in \Z^{n-1}}B_r^{(k)}(k\vec{\omega} + M\vec{t}).
	\end{equation}
	Juntando esto con (\ref{eq:ball-cover:1}) obtenemos lo que queríamos demostrar.
\end{proof}

Ahora bien, denotemos por $\vec{u}_i$ las intersecciones que tiene la capa entera $H_{\vec{q},
\eta\norm{\vec{q}}^{-2}}$ con cada uno de los ejes. Es decir,
\begin{equation*}
	\vec{u}_i \coloneq \frac{\eta}{\vec{q}_i}\vec{e}_i,
\end{equation*}
y consideremos el símplice $\sigma$ generado por estos vectores:
\begin{equation*}
	\sigma \coloneq \left\lbrace \theta_1\vec{u}_1 + \cdots \theta_n\vec{u}_n \colon
		\sum_{i=1}^{n}\theta_i = 1, \theta_i \geq 0 \right\rbrace.
\end{equation*}
No es difícil ver que todo punto $\vec{x} \in \R^n_{\geq \vec{0}}$ sobre la $\eta$-ésima capa entera
también es un elemento de este símplice $\sigma$ y viceversa.

Ahora bien, nos interesa determinar la existencia de un punto entero sobre $\sigma$. De esta manera,
tendríamos un punto entero no negativo que satisface la ecuación lineal diofantina
$\vec{q}^T\vec{x} = \eta$. Para lograr esto, definimos el baricentro del $\sigma$ y
encontramos la máxima distancia que tiene con cualquier otro punto sobre este símplice.

\begin{definition}
	Dado un símplice $\sigma$ generado por $\vec{u}_1, \ldots, \vec{u}_n$, definimos su baricentro
	$\hat{\vec{\sigma}}$ como
	\begin{equation*}
		\hat{\vec{\sigma}} \coloneq \frac{1}{n} \sum_{i=1}^{n}\vec{u}_i.
	\end{equation*}
\end{definition}
\begin{observation}
	El baricentro $\hat{\vec{\sigma}}$ es un elemento de $\sigma$. Esto se debe a que $\hat{\vec{\sigma}}$ es la
	combinación convexa de $\vec{u}_1, \ldots, \vec{u}_n$, donde $\theta_1 = \cdots = \theta_n =
	\frac{1}{n}$.
\end{observation}

\begin{definition}
	Sea $\sigma$ un símplice y consideremos su baricentro $\hat{\vec{\sigma}}$. Definamos
	\begin{equation*}
		r_\sigma \coloneq \max \lbrace r \in \R_{>0} \colon B_r^{(\eta)}(\hat{\vec{\sigma}})
		\subseteq \sigma \rbrace.
	\end{equation*}
	Entonces decimos que $\mathcal{C}^{(\eta)} \coloneq
	B_{r_\sigma}^{(\eta)}(\hat{\vec{\sigma}})$ es la circunferencia inscrita en $\sigma$. A
	$r_\sigma$ le llamamos el radio de tal circunferencia.
\end{definition}

\begin{definition}
	Sea $\sigma$ un símplice. Decimos que $F_j$ es una faceta de $\sigma$ si es el símplice generado
	por los vectores $\lbrace \vec{u}_i \rbrace_{i \neq j}$.
\end{definition}
\begin{observation}
	Si $\sigma$ es generado por $n$ vectores, entonces tiene $\binom{n}{n-1} = n$ facetas, y cada
	una es generada por $n - 1$ vectores. Observemos también que $F_1 \cup \cdots \cup F_n$
	constituye la frontera de $\sigma$.
\end{observation}
\begin{lemma}
	El radio $r_\sigma$ de la circunferencia inscrita en $\sigma$ está dado por
	\begin{equation*}
		r_\sigma = \min_{i} \lbrace d(\hat{\vec{\sigma}}, F_i) \rbrace,
	\end{equation*}
	donde $d(\hat{\vec{\sigma}}, F_i)$ denota la mínima distancia entre el baricentro
	$\hat{\vec{\sigma}}$ y la $i$-ésima faceta $F_i$ del símplice $\sigma$.
\end{lemma}
\begin{proof}
	% TODO: proof
\end{proof}

Recordemos que la distancia entre un punto $\vec{x}$ y un hiperplano afino $F_i$ está dada por
\begin{equation*}
	d(\vec{x}, F_i) = |\vec{\mu}_i^T\vec{x} - b_i|,
\end{equation*}
donde $\vec{\mu}_i$ es el vector unitario normal a $F_i$ que apunta hacia el origen, y $b_i =
\vec{\mu}_i^T\vec{p}_i$, donde $\vec{p}_i$ es un punto sobre $F_i$. De esta manera podemos calcular
el radio de la circunferencia inscrita en $\sigma$.

\begin{theorem}
	Existe un punto entero sobre el símplice $\sigma$ para $\eta$ suficientemente grande.
\end{theorem}
\begin{proof}
	Consideremos $r$ definida en (\ref{eq:radius}). Por el Lema \ref{lemma:ball-cover} sabemos que
	existe un punto entero $\vec{x}$ en $B_r^{(\eta)}(\hat{\vec{\sigma}})$. Como la circunferencia
	$\mathcal{C}^{(\eta)}$ está inscrita en $\sigma$, basta mostrar que existe $\eta$
	suficientemente grande tal que $r \leq r_\sigma$, pues esto implicaría
	\begin{equation*}
		\vec{x} \in B_r^{(\eta)}(\hat{\vec{\sigma}}) \subseteq \mathcal{C}^{(\eta)}{(\hat{\vec{\sigma}})}
		\subseteq \sigma.
	\end{equation*}
\end{proof}

\begin{corollary}
	Para $\eta$ suficientemente grande, la ecuación lineal diofantina $\vec{q}^T\vec{x} = \eta$
	tiene soluciones no negativas.
\end{corollary}

% \begin{lemma}
% 	\label{lemma:bary-dist}
% 	Sea $\sigma$ un símplice generado por $\vec{u}_1, \ldots, \vec{u}_n$ y consideremos su
% 	baricentro $\hat{\vec{\sigma}}$. Entonces
% 	\begin{equation*}
% 		\norm{\hat{\vec{\sigma}} - \vec{x}} \leq \max_{i} \lbrace \norm{\hat{\vec{\sigma}} - \vec{u}_i} \rbrace,
% 	\end{equation*}
% 	para todo $\vec{x} \in \sigma$.
% \end{lemma}
% \begin{proof}
% 	Como $\vec{x}$ es un elemento del símplice $\sigma$, es una combinación convexa de $\vec{u}_1,
% 	\ldots, \vec{u}_n$. Luego,
% 	\begin{equation*}
% 		\vec{x} = \theta_1\vec{u}_1 + \cdots + \theta_n\vec{u}_n,
% 	\end{equation*}
% 	observemos también que
% 	\begin{equation*}
% 		\hat{\vec{\sigma}} = \theta_1\hat{\vec{\sigma}} + \cdots + \theta_n\hat{\vec{\sigma}},
% 	\end{equation*}
% 	pues $\theta_1 + \cdots + \theta_n = 1$. Luego,
% 	\begin{align*}
% 		\norm{\hat{\vec{\sigma}} - \vec{x}}_2
% 		&= \norm{\sum_{i=1}^{n}\theta_i\left(\hat{\vec{\sigma}} - \vec{u}_i\right)}_2 \\
% 		&\leq \sum_{i=1}^{n}\theta_i\norm{\hat{\vec{\sigma}} - \vec{u}_i}_2 \\
% 		&\leq \max_{i}\lbrace \norm{\hat{\vec{\sigma}} - \vec{u}_i}_2 \rbrace  \sum_{i=1}^{n}\theta_i \\
% 		&= \max_{i}\lbrace \norm{\hat{\vec{\sigma}} - \vec{u}_i}_2 \rbrace,
% 	\end{align*}
% 	que es lo que queríamos demostrar.
% \end{proof}
% 
% \begin{theorem}
% 	Para todo $\eta$ suficientemente grande, la ecuación lineal diofantina $\vec{q}^T\vec{x} = \eta$
% 	tiene soluciones enteras no negativas.
% \end{theorem}
% \begin{proof}
% 	Hacemos la demostración por contradicción. Supongamos que no hay ningún punto entero sobre
% 	$\sigma$. Por el Lema \ref{lemma:bary-dist} sabemos que
% 	\begin{equation*}
% 		\norm{\hat{\vec{\sigma}} - \vec{x}}_2 > \max_{i}\lbrace \norm{\hat{\vec{\sigma}} -
% 	\vec{u}_i} \rbrace,
% 	\end{equation*}
% 	para todo punto entero $\vec{x}$ sobre la $\eta$-ésima capa entera $H_{\vec{q},
% 	\eta\norm{\vec{q}}^{-2}}$. Observemos que
% 	\begin{equation*}
% 	\end{equation*}
% \end{proof}

% \begin{definition}
%  Definimos el diámetro $\rho(\sigma)$ de un símplice $\sigma$ como la distancia más grande entre
%  cualesquiera par de puntos sobre $\sigma$. Es decir,
%  \begin{equation*}
%  	\rho(\sigma) \coloneq \max_{\vec{x}, \vec{y} \in \sigma} \lbrace \norm{\vec{y} -
%  	\vec{x}}_2\rbrace.
%  \end{equation*}
% \end{definition}
% \begin{observation}
%  El diámetro $\rho(\sigma)$ está bien definido porque la norma $\norm{\cdot}_2^2$ es una función
%  continua y $\sigma$ es un conjunto compacto, por lo que sí existe el máximo. 
% \end{observation}
% \begin{lemma}
%  El diámetro $\rho(\sigma)$ es igual a la arista de mayor longitud de $\sigma$. Es decir,
%  \begin{equation*}
%  	\rho(\sigma) = \max_{i \neq j} \lbrace \norm{\vec{u}_i - \vec{u}_j}_2 \rbrace.
%  \end{equation*}
% \end{lemma}
% \begin{proof}
%  Sean $\vec{x}, \vec{y} \in \sigma$, de manera que $\vec{y}$ es una combinación convexa de
%  $\vec{u}_i$: 
%  \begin{equation*}
%  	\vec{y} = \theta_1\vec{u}_1 + \cdots + \theta_n\vec{u}_n.
%  \end{equation*}
%  Como $\theta_1 + \cdots + \theta_n = 1$, también se cumple que
%  \begin{equation*}
%  	\vec{x} = \theta_1\vec{x} + \cdots + \theta_n\vec{x}.
%  \end{equation*}
%  Luego,
%  \begin{align*}
%  	\norm{\vec{x} - \vec{y}}_2
%  	&= \norm{\sum_{i=1}^{n}\theta_i\left(\vec{x} - \vec{u}_i\right)}_2 \\
%  	&\leq \sum_{i=1}^{n}\theta_i\norm{\vec{x} - \vec{u}_i}_2 \\
%  	&\leq \max_{i}\lbrace \norm{\vec{x} - \vec{u}_i}_2 \rbrace  \sum_{i=1}^{n}\theta_i \\
%  	&= \max_{i}\lbrace \norm{\vec{x} - \vec{u}_i}_2 \rbrace.
%  \end{align*}
%  Aplicando el mismo razonamiento para $\vec{x}$, obtenemos
%  \begin{equation*}
%  	\norm{\vec{x} - \vec{u}_i}_2 \leq \max_{j \neq i}\lbrace \norm{\vec{u}_j - \vec{u}_i}_2
%  	\rbrace.
%  \end{equation*}
%  Combinando lo anterior, para todo $\vec{x}, \vec{y}$ se sigue que
%  \begin{equation*}
%  	\norm{\vec{x} - \vec{y}}_2 \leq \max_{i}\lbrace \norm{\vec{x} - \vec{u}_i}_2
%  	\rbrace \leq \max_{i}\max_{j \neq i} \lbrace \norm{\vec{u}_j - \vec{u}_i}_2 \rbrace
%  	= \max_{i \neq j} \lbrace \norm{\vec{u}_i - \vec{u}_j} \rbrace.
%  \end{equation*}
%  Por lo tanto, el diámetro de $\sigma$ es igual a la longitud de la arista más grande.
% \end{proof}

\section{Análisis de resultados}
