\chapter{El caso infinito}

% TODO: resumen del capítulo

\section{Una restricción presupuestaria}
\noindent
De acuerdo al Teorema \ref{theory:th:feasibility}, las soluciones del problema
(\ref{theory:formulation}) se encuentran en la $\eta$-ésima capa entera. Así, los puntos enteros que
se encuentran sobre esa capa satisfacen la ecuación lineal diofantina
diofantina
\begin{equation}
	\label{eq:dioph}
	\vec{q}^T\vec{x} = \vec{q}_1\vec{x}_1 + \vec{q}_2\vec{x}_2 + \cdots + \vec{q}_n\vec{x}_n = \eta.
\end{equation}
En la sección de Teoría de Números mostramos bajo qué condiciones existen soluciones a este tipo de
ecuaciones y también cómo construirlas cuando solamente tenemos dos incógnitas. Partimos de la
observación que podemos resolver recursivamente esta ecuación. Definamos, por conveniencia,
$g_1 \coloneq \gcd{\vec{q}_1, \ldots, \vec{q}_n}$ y también $\omega_1 \coloneq \eta$. Como
$\vec{q}_1, \ldots, \vec{q}_n$ son coprimos, sabemos que $g_1 = 1$. Además, definamos
\begin{equation*}
	\omega_2 \coloneq \frac{\vec{q}_2}{g_2 \cdot g_1}\vec{x}_1 + \cdots + \frac{\vec{q}_n}{g_2 \cdot
	g_1}\vec{x}_n,
\end{equation*}
donde $g_2 \coloneq \gcd{\vec{q}_2/g_1, \ldots, \vec{q}_n/g_1}$. Así, la ecuación (\ref{eq:dioph})es
equivalente a
\begin{equation}
	\label{eq:dioph:first-step}
	\frac{q_1}{g_1}\vec{x}_1 + g_2\omega_2 = \omega_1.
\end{equation}
Observemos que
\begin{equation*}
	\gcd{\frac{\vec{q}_1}{g_1}, g_2}
	= \gcd{\frac{\vec{q}_1}{g_1}, \gcd{\frac{\vec{q}_2}{g_1}, \ldots, \frac{\vec{q}_n}{g_1}}}
	= \gcd{\frac{\vec{q}_1}{g_1}, \frac{\vec{q}_2}{g_1}, \ldots, \frac{\vec{q}_n}{g_1}} = 1.
\end{equation*}
Por lo tanto, existen soluciones enteras para todo $\omega_1 \in \Z$. Como $\vec{q}_1/g_1$ y $g_2$
son coprimos, encontramos que sus coeficientes de Bézout asociados (c.f. Definición
\ref{prerreq:def:bezout}) $x_1', \omega_2'$ son soluciones particulares de la ecuación
\begin{equation*}
	\frac{q_1}{g_1}\vec{x}_1 + g_2\omega_2 = 1.
\end{equation*}
Deducimos que las soluciones de la ecuación (\ref{eq:dioph:first-step}) están dadas por
\begin{equation*}
	\begin{cases}
		\vec{x}_1 = \omega_1x_1' + g_2t_1, \\
		\omega_2 = \omega_1\omega_2' - \frac{q_1}{g_1}t_1,
	\end{cases}
\end{equation*}
donde $t_1 \in \Z$ es una variable libre. La restricción de no negatividad $\vec{x}_1 \geq 0$ se debe
satisfacer, así que
\begin{equation*}
	t_1 \geq \left\lceil -\frac{\omega_1x_1'}{g_2} \right\rceil.
\end{equation*}

Para el siguiente paso de la recursión fijamos $t_1$ y resolvemos la ecuación
\begin{equation}
	\label{eq:dioph:second-step}
	\frac{\vec{q}_2}{g_2 \cdot g_1}\vec{x}_2 +
	\frac{\vec{q}_3}{g_2 \cdot g_1}\vec{x}_3 +
	\cdots +
	\frac{\vec{q}_n}{g_2 \cdot g_1}\vec{x}_n
	= \omega_2.
\end{equation}
Como $g_2 = \gcd{\vec{q}_2/g_1, \ldots, \vec{q}_n/g_1}$, sabemos del Corolario \ref{prerreq:cor:gcd}
que
\begin{equation*}
	\gcd{\frac{\vec{q}_2}{g_2 \cdot g_1}, \ldots, \frac{\vec{q}_n}{g_2 \cdot g_1}} = 1.
\end{equation*}
En el mismo espíritu que el primer paso de la recursión, definimos
\begin{equation*}
	\omega_3 \coloneq \frac{\vec{q}_3}{g_3 \cdot g_2 \cdot g_1}\vec{x}_1 + \cdots + \frac{\vec{q}_n}{g_3
	\cdot g_2 \cdot g_1}\vec{x}_n,
\end{equation*}
donde
\begin{equation*}
	g_3 \coloneq  \gcd{\frac{\vec{q}_3}{g_2 \cdot g_1}, \ldots, \frac{\vec{q}_n}{g_2 \cdot g_1}}.
\end{equation*}
Por lo que la ecuación (\ref{eq:dioph:second-step}) es equivalente a
\begin{equation}
	\label{eq:dioph:second-step:short}
	\frac{\vec{q}_2}{g_2 \cdot g_1}\vec{x}_2 + g_3\omega_3 = \omega_2.
\end{equation}
Nuevamente, tenemos
\begin{equation*}
	\gcd{\frac{\vec{q}_2}{g_2 \cdot g_1}, g_3} = 1,
\end{equation*}
y entonces (\ref{eq:dioph:second-step:short}) tiene una infinidad de soluciones para todo $\omega_2 \in
\Z$, las cuales están dadas por
\begin{equation*}
	\begin{cases}
		\vec{x}_2 = \omega_2x_2' + g_3t_2, \\
		\omega_3 = \omega_2\omega_3' - \frac{q_2}{g_2 \cdot g_1}t_2,
	\end{cases}
\end{equation*}
donde $t_2 \in \Z$ es una variable libre, y $x_2', \omega_3'$ son los coeficientes de Bézout
asociados a $\frac{\vec{q}_2}{g_2 \cdot g_2}$ y $g_3$, respectivamente. Por la restricción de no
negatividad $\vec{x}_2 \geq 0$ se debe satisfacer
\begin{equation*}
	t_2 \geq \left\lceil -\frac{\omega_2x_2'}{g_3} \right\rceil.
\end{equation*}

De manera general, para $i \in \lbrace 1, \ldots, n - 2 \rbrace$, el $i$-ésimo paso de la recursión
provee las soluciones
\begin{equation}
	\label{eq:recurrence}
	\begin{cases}
		\vec{x}_i = \omega_ix_i' + g_{i + 1}t_i, \\
		\omega_{i + 1} = \omega_i\omega_{i + 1}' - \frac{\vec{q}_i}{\prod_{j=1}^{i}g_j}t_i,
	\end{cases}
\end{equation}
donde $t_i \in \Z$ satisface, debido a la restricción de no negatividad $\vec{x}_i \geq 0$,
\begin{equation}
	\label{eq:param-lb}
	t_i \geq \left\lceil -\frac{\omega_ix_i'}{g_{i + 1}} \right\rceil.
\end{equation}

En el último paso obtenemos la ecuación lineal diofantina
\begin{equation}
	\label{eq:last-equation}
	\frac{q_{n-1}}{\prod_{j=1}^{n-1}g_j}\vec{x}_{n-1} +
	\frac{q_{n}}{\prod_{j=1}^{n-1}g_j}\vec{x}_n
	= \omega_{n-1}.
\end{equation}
Por construcción, los coeficientes de $\vec{x}_{n - 1}$ y $\vec{x}_n$ son coprimos. Las soluciones
están dadas por
\begin{equation}
	\label{eq:last-solution}
	\begin{cases}
		\vec{x}_{n-1} = \omega_{n-1}x_{n-1}' + \frac{\vec{q}_n}{\prod_{j=1}^{n-1}g_j}t_{n-1}, \\
		\vec{x}_n = \omega_{n-1}x_n' - \frac{\vec{q}_{n-1}}{\prod_{j=1}^{n-1}g_j}t_{n-1},
	\end{cases}
\end{equation}
Para que ahora se satisfagan las condiciones de no negatividad de $\vec{x}_{n-1}$ y de $\vec{x}_n$,
encontramos que la variable libre $t_{n-1} \in \Z$ debe cumplir ciertas desigualdades según los
signos de $\vec{q}_{n-1}$ y de $\vec{q}_n$. Definamos, por conveniencia,
\begin{equation}
	\label{eq:lr-bounds}
	b_1 \coloneq -\frac{\omega_{n-1}x_{n-1}'}{\vec{q}_n} \cdot \prod_{j=1}^{n-1}g_j,
	\quad b_2 \coloneq \frac{\omega_{n-1}x_{n}'}{\vec{q}_{n-1}} \cdot \prod_{j=1}^{n-1}g_j.
\end{equation}
Entonces se verifica que
\begin{equation}
	\label{eq:feasible-param}
	t_{n-1} \in 
	\begin{cases}
		\big[ \lceil b_1 \rceil, \lfloor b_2 \rfloor \big] & \text{si } 0 < \vec{q}_{n-1}, \vec{q}_n, \\
		\big[ \lceil b_2 \rceil, \lfloor b_1 \rfloor \big] & \text{si } \vec{q}_{n-1}, \vec{q}_n < 0, \\
		\big[ \lceil \max\lbrace b_1 ,  b_2 \rbrace \rceil, \infty \big) & \text{si } \vec{q}_{n-1}
		< 0 < \vec{q}_n, \\
		\big( -\infty, \lfloor \min\lbrace b_1, b_2\rbrace \rfloor \big] & \text{si } \vec{q}_n < 0
		< \vec{q}_{n-1}.
	\end{cases}
\end{equation}

\begin{lemma}
	\label{lemma:t-existence}
	Existe un vector $\vec{t} \in \Z^{n-1}$ que satisface ambos (\ref{eq:param-lb}) y
	(\ref{eq:feasible-param}).
\end{lemma}
\begin{proof}
	Tenemos cuatro casos, pero observemos que los dos en donde $\vec{q}_{n - 1}$ y $\vec{q}_n$
	tienen signo distinto no son difíciles: si $\vec{q}_{n - 1} <0 < \vec{q}_n$, entonces el vector
	$\vec{t} \in \Z^{n-1}$ dado por
	\begin{equation*}
		\vec{t}_i \coloneq \begin{cases}
			\left\lceil -\frac{\omega_i x_i'}{g_{i + 1}} \right\rceil, & i < n - 1, \\
			\lceil \max\lbrace b_1, b_2 \rbrace \rceil, & i = n - 1,
		\end{cases}
	\end{equation*}
	satisface ambos (\ref{eq:param-lb}) y (\ref{eq:feasible-param}). El caso $\vec{q}_n < 0 <
	\vec{q}_{n - 1}$ es completamente similar.

	Ahora bien, supongamos que $0 < \vec{q}_{n - 1}, \vec{q}_n$. Podemos suponer sin pérdida de
	generalidad que $\vec{q}_{n - 2} < 0$. En efecto, como $\vec{q}_i < 0$ para alguna $i \in
	\lbrace 2, \ldots, n \rbrace$, somos capaces permutar las entradas $i$ y $n - 2$ de $\vec{q}$ en
	el problema (\ref{theory:formulation}). Observemos que
	\begin{align*}
		b_2 - 1 &\leq \lfloor b_2 \rfloor \leq b_2, \\
		b_1 &\leq \lceil b_1 \rceil \leq b_1 + 1.
	\end{align*}
	De donde obtenemos
	\begin{equation*}
		b_2 - b_1 - 2 \leq \lfloor b_2 \rfloor - \lceil b_1 \rceil \leq b_2 - b_1.
	\end{equation*}
	Así pues, para que el intervalo $[\lceil b_1 \rceil, \lfloor b_2 \rfloor]$ esté bien definido,
	es suficiente con mostrar que existe un escalar $\omega_{n - 1}$ que satisfaga $b_2 - b_1 \geq
	2$. Tenemos
	\begin{equation}
		\label{proof:b-sub}
		b_2 - b_1 = \omega_{n - 1}\prod_{j = 1}^{n-1}g_j \cdot
			\left(\frac{x_{n-1}'}{\vec{q}_n} + \frac{x_n'}{\vec{q}_{n - 1}}\right)
	\end{equation}
	Como $x_{n - 1}'$ y $x_n'$ son coeficientes de Bézout asociados a los dos coeficientes en
	(\ref{eq:last-equation}) que son coprimos, se cumple
	\begin{equation*}
		\frac{\vec{q}_{n - 1}}{\prod_{j = 1}^{n-1}g_j}x_{n-1}' +
		\frac{\vec{q}_{n}}{\prod_{j = 1}^{n-1}g_j}x_{n}' = 1,
	\end{equation*}
	lo que implica que
	\begin{equation*}
		\frac{x_{n-1}'}{\vec{q}_n} + \frac{x_n'}{\vec{q}_{n - 1}} = \frac{\prod_{j =
		1}^{n-1}g_j}{\vec{q}_{n-1}\vec{q}_n}.
	\end{equation*}
	Sustituyendo en (\ref{proof:b-sub}),
	\begin{equation}
		\label{proof:omega-sub}
		b_2 - b_1 = \omega_{n-1}\cdot \frac{\prod_{j=1}^{n-1}g_j^2}{\vec{q}_{n-1}\vec{q}_n} \geq 2
		\iff \omega_{n-1} \geq 2\frac{\vec{q}_{n-1}\vec{q}_n}{\prod_{j=1}^{n-1}g_j^2}.
	\end{equation}
	De (\ref{eq:recurrence}) sabemos que
	\begin{equation*}
		\omega_{n-1} = \omega_{n-2}\omega_{n-1}' -
		\frac{\vec{q}_{n-2}}{\prod_{j=1}^{n-2}g_j}t_{n-2}.
	\end{equation*}
	Sustituyendo en (\ref{proof:omega-sub}), usando el hecho de que $\vec{q}_{n-2} < 0$ y despejando
	$t_{n-2}$, encontramos que $\lceil b_2 \rceil - \lfloor b_1 \rfloor \geq 0$ si
	\begin{equation*}
		t_{n-2} \geq \frac{\omega_{n-2}\omega_{n-1}'}{\vec{q}_{n-2}}\prod_{j=1}^{n-2}g_j
		- 2\frac{\vec{q}_{n-1}\vec{q}_n}{\vec{q}_{n-2}g_{n-1}^2}
		\prod_{j=1}^{n-2}g_j^{-1}
	\end{equation*}
	Llamemos $c$ al lado derecho de esta desigualdad. Así pues, definimos el vector
	$\vec{t} \in \Z^{n-1}$ de manera que
	\begin{equation*}
		\vec{t}_i \coloneq \begin{cases}
			\left\lceil -\frac{\omega_i x_i'}{\vec{q}_i} \right\rceil, & i < n - 2, \\[1em]
			\left\lceil \max\left\lbrace -\frac{\omega_ix_i'}{\vec{q}_i}, c \right\rbrace
			\right\rceil, & i = n -2, \\[0.8em]
			\lceil b_1 \rceil, & i = n - 1.
		\end{cases}
	\end{equation*}
	Se verifica que $\vec{t}$ satisface ambos (\ref{eq:param-lb}) y (\ref{eq:feasible-param}).
	Finalmente, el caso $\vec{q}_{n-1}, \vec{q}_n < 0$ es completamente similar.
\end{proof}

En síntesis, por el Teorema (\ref{theory:th:feasibility}) sabemos que la solución se encuentra en
la $\eta$-ésima capa entera. Por lo tanto, debemos encontrar una solución no negativa a la ecuación
lineal diofantina (\ref{eq:dioph}). Por el Lema \ref{lemma:t-existence} sabemos que existe un vector
$\vec{t} \in \Z^{n-1}$ que satisface ambos (\ref{eq:param-lb}) y (\ref{eq:feasible-param}). Si
definimos $\vec{x}$ como lo indican (\ref{eq:recurrence}) y (\ref{eq:last-solution}) usando
$\vec{t}$, entonces $\vec{x}$ es una solución entera no negativa. Observemos que podemos construir
los vectores $\vec{t}$ y $\vec{x}$ simúltaneamente. De esta manera, obtenemos el siguiente Teorema.

\begin{theorem}
	\label{infinite:th:complexity}
	El problema (\ref{theory:formulation}) se puede resolver a través de encontrar la solución de
	una ecuación lineal diofantina en $n$ incógnitas.
\end{theorem}

\section{Múltiples restricciones}
\noindent
En esta sección hacemos una discusión extensiva sobre la dificultad de agregar más restricciones al
problema (\ref{theory:formulation}). El autor considera que es de suma importancia mostrar los
``puntos débiles'' en lo que llevamos construido de teoría hasta este punto. A causa de la falta de
resultados fuertes y concretos, creemos que es sensato hacer el estilo de esta discusión más
relajado y un tanto informal.

Sea $A \in \Q^{m \times n}$ una matriz racional con renglones linealmente independientes y sea $b
\in \Q^m$ un vector. Consideremos el problema
\begin{subequations}
	\label{formulation:multiple}
	\begin{align}
		\max_{\vec{x} \in \Z^n} \quad
			& \vec{p}^T\vec{x}, \label{formulation:multiple:objective} \\
		\text{s.a.} \quad
			& \vec{p}^T\vec{x} \leq u, \label{formulation:multiple:constraint:budget} \\
			& A\vec{p} = \vec{b}, \label{formulation:multiple:constraints} \\
			& \vec{x} \geq \vec{0}. \nonumber
	\end{align}
\end{subequations}
En el caso donde solamente estaba presente la restricción presupuestaria, encontramos una relación
entre el vector de soluciones $\vec{x} \in \Z^n$ y el vector de variables libres $\vec{t} \in
\Z^{n-1}$. Hemos manejado esta relación de manera recursiva. En la primera parte de esta sección
buscamos exhibir una transformación afina entre estos dos vectores. A partir de ello, plantearemos
un problema de maximización sobre $\vec{t}$ y analizaremos cómo su solución se relaciona con la de
este problema más general.

Nuevamente, añadimos la condición de que $\vec{p}$ sea esencialmente entero y dejamos que $\vec{q}$
sea su múltiplo coprimo con $\vec{q}_i < 0$ para alguna $i \in \lbrace 2, \ldots, n \rbrace$. De
ahora en adelante, nos concentramos en $\vec{q}$ en vez de $\vec{p}$. Ciertamente, la solución no se
encuentra necesariamente en la $\eta$-ésima capa entera. Por ejemplo, si dejamos que $A \coloneq
\vec{q}^T$ y $b \coloneq u - m$, la solución se encontrará en la $\xi$-ésima capa entera, donde
\begin{equation*}
	\xi \coloneq \left\lfloor \frac{u}{m} - 1 \right\rfloor < \eta.
\end{equation*}
No obstante, si el problema (\ref{formulation:multiple}) es factible, sabemos que la solución se
encontrará en alguna capa entera con parámetro $k \in \lbrace \eta, \eta - 1, \ldots \rbrace$, pues
todavía contamos con una restricción presupuestaria que se debe satisfacer.

En primer lugar, buscamos establecer una relación lineal entre $\vec{t}$ y $\vec{x}$ que permita
deshacernos de la restricción presupuestaria. Para ello, nos fijamos en la $k$-ésima capa entera y
resolvemos la ecuación lineal diofantina
\begin{equation*}
	\vec{q}_1\vec{x}_1 + \cdots \vec{q}_n\vec{x}_n = k.
\end{equation*}
Observemos que la única diferencia entre esta ecuación y (\ref{eq:dioph}) es el lado derecho de la
igualdad. Entonces, podemos hacer uso de los resultados anteriores si definimos $\omega_1 \coloneq
k$ en vez de $\omega_1 \coloneq \eta$. A partir de esto último junto con (\ref{eq:recurrence}),
descubrimos una relación de recurrencia que los coeficientes $\omega_i$ deben satisfacer:
\begin{equation}
	\label{eq:omega-recurrence}
	\begin{cases}
		\omega_1 &= k, \\
		\omega_{i + 1} &= \omega_i \cdot \omega_{i + 1}' - \frac{\vec{q}_i}{\prod_{\ell=1}^{i}g_\ell} \cdot t_i.
	\end{cases}
\end{equation}
\begin{lemma}
	La forma cerrada de la relación de recurrencia (\ref{eq:omega-recurrence}) está dada por
	\begin{equation}
		\label{eq:omega-formula}
		\omega_i =
		k \cdot \prod_{j=2}^{i} \omega_j'
		- \sum_{j=1}^{i - 1}\frac{\vec{q}_j}{\prod_{\ell=1}^{j}g_\ell}
		\cdot \prod_{\ell=j+2}^{i}\omega_\ell' \cdot t_j.
	\end{equation}
	Donde, por conveniencia, le asignamos el valor de 0 a la suma vacía y el valor de 1 al producto
	vacío.
\end{lemma}
\begin{proof}
	Lo demostramos inductivamente. Observemos que
	\begin{equation*}
		\omega_1 =
		k \cdot \prod_{j=2}^{1} \omega_j'
		- \sum_{j=1}^{0}\frac{\vec{q}_j}{\prod_{\ell=1}^{j}g_\ell}
		\cdot \prod_{\ell=j+2}^{1}\omega_\ell' \cdot t_j
		= k,
	\end{equation*}
	debido a que definimos el producto vacío como 1 y la suma vacía como 0. Supongamos
	inductivamente que (\ref{eq:omega-formula}) se satisface para alguna $i \in \N$. Entonces,
	tenemos
	\begin{align*}
		\omega_{i + 1}
		&=
		k \cdot \prod_{j=2}^{i + 1} \omega_j'
		- \sum_{j=1}^{i}\frac{\vec{q}_j}{\prod_{\ell=1}^{j}g_\ell}
		\cdot \prod_{\ell=j+2}^{i + 1}\omega_\ell' \cdot t_j \\
		&=
		k \cdot \prod_{j=2}^{i} \omega_j' \cdot \omega_{i+1}
		- \sum_{j=1}^{i - 1}\frac{\vec{q}_j}{\prod_{\ell=1}^{j}g_\ell}
		\cdot \prod_{\ell=j+2}^{i}\omega_\ell' \cdot t_j \cdot \omega_{i + 1}'
		- \frac{\vec{q}_i}{\prod_{\ell = 1}^{i}g_\ell}
		\cdot \prod_{\ell = i + 2}^{i + 1}\omega_\ell' \cdot t_i \\
		&= 
		\left( k \cdot \prod_{j=2}^{i} \omega_j'
		- \sum_{j=1}^{i - 1}\frac{\vec{q}_j}{\prod_{\ell=1}^{j}g_\ell}
		\cdot \prod_{\ell=j+2}^{i}\omega_\ell' \cdot t_j \right) \omega_{i+1}'
		- \frac{\vec{q}_i}{\prod_{\ell = 1}^{i}g_\ell} \cdot t_i  \\
		&= \omega_i \cdot \omega_{i + 1}' - \frac{\vec{q}_i}{\prod_{\ell = 1}^{i}g_\ell} \cdot t_i.
	\end{align*}
	Por el principio de inducción se sigue que (\ref{eq:omega-formula}) satisface
	(\ref{eq:omega-recurrence}) para todo $i \in \N$. Así, esta fórmula es la forma cerrada de la
	relación de recurrencia propuesta.
\end{proof}

Por conveniencia, definimos los coeficientes $m_{ij} \in \mathbb{Z}$ con $i > j$ como
\begin{equation}
	\label{phase-2:eq:coeffs}
	m_{ij} \coloneq \frac{\vec{q}_j}{\prod_{\ell = 1}^{j}g_\ell} \cdot \prod_{\ell = j +
	2}^{i}\omega_\ell'.
\end{equation}
Así pues, juntando esto último con \ref{eq:recurrence}, obtenemos para $i \in \{1, \ldots, n -
2\}$, 
\begin{align}
	\vec{x}_i &= \omega_i \cdot x_i' + g_{i + 1}\vec{t}_i \nonumber \\
		&= k \cdot \prod_{j=2}^{i}\omega_j' \cdot x_i' - \sum_{j=1}^{i - 1}m_{ij}x_i'
		\vec{t}_j + g_{i + 1}\vec{t}_i \label{eq:x:i}.
\end{align}
Similarmente, sustituyendo en \ref{eq:last-solution},
\begin{subequations}
	\label{eq:x:last}
	\begin{align}
		\vec{x}_{n-1} &= k \cdot \prod_{j=2}^{n-1} \omega_j' \cdot x_{n-1}' - \sum_{j=1}^{n-2}
		m_{n-1,j}x_{n-1}' \vec{t}_j + \frac{\vec{q}_n}{\prod_{j=1}^{n-2}g_j} \vec{t}_{n-1}, \\
		\vec{x}_{n} &= k \cdot \prod_{j=2}^{n-1} \omega_j' \cdot x_{n}' - \sum_{j=1}^{n-2}
		m_{n,j}x_{n}' \vec{t}_j - \frac{\vec{q}_{n - 1}}{\prod_{j=1}^{n-2}g_j} \vec{t}_{n-1}.
	\end{align}
\end{subequations}

Con este trabajo anterior, ya podemos establecer una relación lineal entre $\vec{t} \in \Z^{n-1}$ y
$\vec{x} \in \Z^n$. Definimos $\vec{\omega} \in \Z^n$ como
\begin{equation}
	\label{eq:vec-omega}
	\vec{\omega}_i \coloneq \vec{x}_i' \cdot \prod_{j = 2}^{\min{\lbrace i, n - 1 \rbrace}}\omega_j'.
\end{equation}
También definimos la matriz $M \in \Z^{n \times (n - 1)}$ a través de
\begin{equation}
	\label{eq:mat-T}
	M_{ij} \coloneq \begin{cases}
		-m_{ij}x_i', &\quad j < i, \\
		g_{i + 1},  &\quad i = j < n - 1, \\
		\frac{\vec{q}_n}{\prod_{k=1}^{n-2}g_k}, &\quad i = j = n - 1, \\
		-\frac{\vec{q}_{n-1}}{\prod_{k=1}^{n-2}g_k}, &\quad i = n, j = n - 1, \\
		0, &\quad \text{e.o.c.}
	\end{cases}
\end{equation}
De (\ref{eq:x:i}) y (\ref{eq:x:last}) encontramos que
\begin{equation}
	\label{eq:transf}
	\vec{x} = k\vec{\omega} + M\vec{t}.
\end{equation}
Observemos que $M$ es triangular inferior cuya diagonal principal es distinta de cero. En efecto, la
entrada $M_{ii} = g_{i + 1}$ para $i \in \lbrace 1, \ldots, n - 2 \rbrace$ representa el máximo
común divisor, el cual siempre es positivo, además, supusimos que $\vec{q}$ no contiene entradas
nulas, por lo que $M_{n-1,n-1}$ es distinta de cero. A partir de ello, deducimos que las columnas de
$M$ son linealmente independientes.

\begin{lemma}
	\label{lemma:iso1}
	El vector $\vec{\omega} \in \Z^n$ satisface $\vec{q}^T\vec{\omega} = 1$.
\end{lemma}
\begin{proof}
	Primero mostramos por inducción hacía atrás que se cumple
	\begin{equation}
		\label{eq:omega-induction}
		\sum_{j=i}^{n}\vec{q}_j\vec{\omega_j} = \prod_{j=2}^{i}\omega_j' \cdot \prod_{j=1}^{i}g_j,
	\end{equation}
	para todo $i \in \lbrace 1, \ldots, n - 1\rbrace$. Empezamos con el caso base $i = n - 1$:
	\begin{equation}
		\label{eq:omega-base-case}
		\vec{q}_{n-1}\vec{\omega}_{n-1} + \vec{q}_n\omega_n 
		= \prod_{j=2}^{n-1}\omega_j' \cdot \left(\vec{q_{n-1}}x_{n-1}' + \vec{q}_nx_n'\right).
	\end{equation}
	Como $x_{n-1}'$ y $x_n'$ son coeficientes de Bézout asociados a los coeficientes del lado
	izquierdo de (\ref{eq:last-equation}), los cuales son coprimos, y por lo tanto satisfacen
	\begin{equation*}
		\frac{\vec{q}_{n-1}}{\prod_{j=1}^{n-1}g_j}x_{n-1}' +
		\frac{\vec{q}_n}{\prod_{j=1}^{n-1}g_j}x_n' = 1
		\implies
		\vec{q}_{n-1}x_{n-1}' + \vec{q}_nx_n' = \prod_{j=1}^{n-1}g_j.
	\end{equation*}
	Sustituyendo en (\ref{eq:omega-base-case}), obtenemos
	\begin{equation*}
		\prod_{j=2}^{n-1}\omega_j' \cdot \prod_{j=1}^{n-1}g_j.
	\end{equation*}
	Supongamos inductivamente que (\ref{eq:omega-induction}) se satisface para alguna $2 \leq i \leq
	n - 1$. Entonces tenemos
	\begin{align*}
		\sum_{j=i-1}^{n}\vec{q}_j\vec{\omega}_j
		&= \vec{q}_{i-1}\vec{\omega}_{i-1} + \sum_{j=i}^{n}\vec{q}_j\vec{\omega_j} \\
		&= \prod_{j=2}^{i-1}\omega_j' \cdot \vec{q}_{i-1}x_{i-1}' + \prod_{j=2}^{i}\omega_j' \cdot
		\prod_{j=1}^{i}g_j \\
		&= \prod_{j=2}^{i-1}\omega_j' \cdot \left( \vec{q}_{i-1}x_{i-1}' + \omega_i'
			\prod_{j=1}^{i}g_j \right).
	\end{align*}
	Nuevamente, $x_{i-1}'$ y $\omega_i'$ son coeficientes de Bézout asociados, respectivamente, a
	$\frac{\vec{q}_i}{\prod_{j=1}^{i-1}}$ y $g_i$, los cuales son coprimos. De esta manera
	satisfacen
	\begin{equation*}
		\frac{\vec{q}_{i-1}}{\prod_{j=1}^{i-1}g_j}x_{i-1}' +
		g_i \omega_i' = 1
		\implies
		\vec{q}_{i-1}x_{i-1}' + g_i\prod_{j=1}{i}\omega_j' = \prod_{j=1}^{i-1}g_j.
	\end{equation*}
	Sustituyendo, obtenemos el resultado (\ref{eq:omega-induction}) para $i - 1$. Así, por inducción
	hacía atrás, (\ref{eq:omega-induction}) se cumple para todo $i \in \lbrace 1, \ldots, n - 1
	\rbrace$. Finalmente, para demostrar el Lema, observamos que
	\begin{equation*}
		\vec{q}^T\vec{\omega} = \sum_{j=1}^{n}\vec{q}_j\vec{\omega}_j = \prod_{j=2}^{1}\omega_j'
		\cdot \prod_{j=1}^{1}g_j = g_1 = 1.
	\end{equation*}
	El primer producto es uno por ser el producto vacío. Recordemos también que $g_1$ es el máximo
	común divisor de $\vec{q}_1, \ldots, \vec{q}_n$, los cuales son coprimos, y entonces $g_1 = 1$.
\end{proof}
\begin{corollary}
	\label{cor:iso2}
	El vector $\vec{q}$ genera el espacio ortogonal a la imagen de $M$.
\end{corollary}
\begin{proof}
	Como $M$ tiene $n - 1$ columnas linealmente independientes, su imagen tiene dimensión $n - 1$ y,
	por lo tanto, el espacio ortogonal a su imagen tiene dimensión 1. Así, basta mostrar que
	$\vec{q} \in \ker{M^T}$.

	Sea $\vec{x} \in \Z^n$. Por el Teorema \ref{phase-1:th:cover}, existe una capa entera
	$H_{\vec{q}, k\norm{\vec{q}}^{-2}}$ que contiene a $\vec{x}$. Así, $\vec{x}$ satisface la
	ecuación lineal diofantina $\vec{q}^T\vec{x} = k$. Por construcción, existen $\vec{\omega} \in
	\Z^n$ y $\vec{t} \in \Z^{n-1}$ tal que $\vec{x} = k\vec{\omega} + M\vec{t}$. Luego,
	\begin{equation*}
		k = \vec{q}^T\vec{x} = k \vec{q}^T\vec{\omega} + \vec{q}^TM\vec{t} = k +
		(\vec{q}^TM)\vec{t}.
	\end{equation*}
	De donde obtenemos $(\vec{q}^TM)\vec{t} = 0$. Pero $\vec{x}$ fue arbitrario, así que también lo
	fue $\vec{t}$. Entonces se debe cumplir $\vec{q}^TM = 0$, lo que implica que $\vec{q} \in
	\ker{M^T}$.
\end{proof}

Geométricamente, a partir de $\vec{q}$ descomponemos el espacio $\Z^n$ como una suma de dos espacios
isomorfos a $\Z$ y a $\Z^{n-1}$, los cuales son generados por $\vec{\omega}$ y las columnas de $M$,
respectivamente. El vector $k\vec{\omega}$ es una solución particular a la ecuación no homogénea
$\vec{q}^T\vec{\omega} = 1$, mientras que los renglones de $M$ forman una base del conjunto de
soluciones de la ecuación homogénea $\vec{q}^T\vec{m} = 0$. Como $\vec{q}$ es un vector coprimo
arbitrario, tenemos que cualquier vector coprimo (y, por extensión, cualquier vector esencialmente
entero) induce una descomposición en $\Z^n$. Ciertamente, esta idea de descomponer el espacio
completo a partir de soluciones particulares y homogéneas no es novedosa.

Ahora bien, en el contexto del problema (\ref{formulation:multiple}), el parámetro $k \in \Z$ se
encarga de maximizar la utilidad (\ref{formulation:multiple:objective}), así como de respetar el
presupuesto (\ref{formulation:multiple:constraint:budget}) a través de $k \leq \eta$. Similarmente,
el vector $t \in \Z^{n-1}$ se encarga de respetar las otras restricciones
(\ref{formulation:multiple:constraints}).
\begin{theorem}
	El problema (\ref{formulation:multiple}) es equivalente al problema de maximización
	\begin{subequations}
		\label{formulation:lattice}
		\begin{align}
			\max_{k \in \Z, \vec{t} \in \Z^{n-1}}
				& k, \\
			\text{s.a.} \quad
				& k \leq \eta, \label{lattice:c-layer} \\
				& AM\vec{t} = kA\vec{\omega} - \vec{b}, \label{lattice:constraints} \\
				& M\vec{t} \geq -k\vec{\omega}.
		\end{align}
	\end{subequations}
\end{theorem}
\begin{proof}
	Por la discusión anterior, sabemos que la transformación lineal
	\begin{align*}
		T \vcentcolon &\Z + \Z^{n-1} \rightarrow \Z^n \\
		(k, \vec{t}) &\mapsto x \coloneq k\vec{\omega} + M\vec{t}
	\end{align*}
	es un isomorfismo. Así, tenemos
	\begin{align*}
		A\vec{x} = \vec{b} &\iff AM\vec{t} = \vec{b} - kA\vec{\omega}, \\
		\vec{x} \geq \vec{0} &\iff M\vec{t} \geq -k\vec{\omega},
	\end{align*}
	y por lo tanto basta mostrar que si un vector es factible para un problema, entonces satisface
	la correspondiente restricción presupuestaria del otro problema. También recordemos que $\eta$
	parametriza la primera capa entera que satisface el presupuesto.

	Sea $\vec{x} \in \Z^n$ un vector factible de (\ref{formulation:multiple}) Como $\vec{x}$ es
	entero, entonces se debe cumplir $\vec{q}^T\vec{x} \leq \eta$. Ahora bien, existe $(k, \vec{t})
	\in \Z^n$ que satisface $\vec{x} = k\vec{\omega} + M\vec{t}$. Por el Lema \ref{lemma:iso1} y el
	Corolario \ref{cor:iso2} encontramos que
	\begin{equation*}
		k = \vec{q}^T\vec{x} \leq \eta,
	\end{equation*}
	y entonces $(k, \vec{t})$ es factible. Como $\vec{x}$ fue arbitrario, se sigue que la solución
	del problema (\ref{formulation:multiple}) es una cota inferior del problema
	(\ref{formulation:lattice}). La demostración de que la solución de (\ref{formulation:lattice})
	es una cota inferior de (\ref{formulation:multiple}) es análoga.

	Finalmente, supongamos que $(k, \vec{t}) \in \Z^n$ es solución de (\ref{formulation:lattice}).
	Si existe $\hat{\vec{x}}$ factible para (\ref{formulation:multiple}) con utilidad
	$\vec{q}^T\hat{\vec{x}} = \hat{k}$ estrictamente mayor, entonces consideramos $(\hat{k},
	\hat{\vec{t}})$ tal que $\hat{\vec{x}} = \hat{k}\vec{\omega} + M\hat{\vec{t}}$. Este vector
	también es factible con utilidad $k < \hat{k} \leq \eta$, y entonces $(k, \vec{t})$ no era la
	solución de (\ref{formulation:lattice}). Obtenemos una contradicción.
\end{proof}

La formulación del problema equivalente en el Teorema anterior resulta ser más interesante. En
primer lugar, observemos que el vector objetivo todavía es ortogonal a la restricción
presupuestaria. No obstante, es más fácil de manejar en caso de usar cortes como en Ramificación y
Acotamiento. Si $k^*$ no es entero en la solución al problema relajado, la única manera de ramificar
es con el nuevo corte $k \leq \lfloor k^* \rfloor$, pues el otro corte $k \geq \lceil k^* \rceil$
no es válido. Evidentemente, en la sección de análisis de resultados haremos comparaciones de tiempo
en los tiempos de terminación entre esta formulación y la original.

En segundo lugar, podemos desacoplar esta nueva formulación de manera que obtengamos un problema de
maximización y otro de factibilidad.

Supongamos, sin pérdida de generalidad, que las entradas de $A$ y $\vec{b}$ son enteras. Como los
renglones de $A$ son linealmente independientes, de \cite{alex} sabemos que tiene una única
factorización de Hermite. Es decir, existe una matriz $U \in \Z^{n \times n}$ unimodular que
satisface $AU = [H, \vec{0}]$, donde $H \in \Z^{m \times m}$ es triangular inferior y no singular.

Consideremos el subproblema
\begin{subequations}
	\label{subformulation:lattice}
	\begin{align}
		\max_{k \in \Z}
			& ~ k, \\
		\text{s.a.} \quad
		k &\leq \eta, \\
			A\tilde{\vec{y}} &= kA\vec{\omega} - \vec{b},
	\end{align}
\end{subequations}
donde 
\begin{equation*}
	\tilde{\vec{y}} \coloneq U \begin{pmatrix} \tilde{\vec{y}}_m \\ \tilde{\vec{y}}_{n-m} \end{pmatrix}
	= U_m\tilde{\vec{y}}_m + U_{n-m}\tilde{\vec{y}}_{n-m} \in \Z^n,
\end{equation*}
con $\tilde{\vec{y}}_m \in \Z^m$ y $\tilde{\vec{y}}_{n-m} \in \Z^{n-m}$. Así también, $U_m$ y
$U_{n-m}$ denotan las primeras $m$ columnas y últimas $n - m$ columnas, respectivamente. Observemos
que para toda $k \in \Z$ se cumple
\begin{equation}
	AU \begin{pmatrix} \inv{H}\left(kA\vec{\omega} - \vec{b}\right) \\ \tilde{\vec{y}}_{n-m} \end{pmatrix}
	=
	[H, \vec{0}] \begin{pmatrix} \inv{H}\left(kA\vec{\omega} - \vec{b}\right) \\ \tilde{\vec{y}}_{n-m} \end{pmatrix}
	= kA\vec{\omega} - \vec{b}
\end{equation}
Para
definir a $\tilde{\vec{y}}_m$ de esa manera, debemos asegurarnos también que sea entero. Observemos
que $\tilde{\vec{y}}_{n-m}$ queda libre, así que en realidad este subproblema tiene dimensión $m +
1$. Definimos el conjunto de factibilidad
\begin{equation}
	\label{eq:feas-set}
	F \coloneq \lbrace k \in \Z \vcentcolon \inv{H}\left(kA\vec{\omega} - \vec{b}\right) \in \Z^m \rbrace
	\cap \lbrace k \in \Z \vcentcolon k \leq \eta \rbrace.
\end{equation}
\begin{observation}
	Para que $F$ no sea vacío, debe existir $k \in \Z$ tal que $\det(H) \mid (k\vec{a}_j^T
	\vec{\omega} - \vec{b}_j)$ para todo $j \in \lbrace 1, \ldots, m \rbrace$, donde $\vec{a}_j$
	denota el $j$-ésimo renglón de $A$. Es decir, $k$ debe satisfacer
	\begin{equation*}
		\det(H) \mid \gcd{k\vec{a}_1^T\vec{\omega} - b_1, \ldots, k\vec{a}_m^T\vec{\omega} - b_m}.
	\end{equation*}
	Ahora bien, $H$ es triangular inferior e invertible, por lo que $\det(H) \neq 0$ es el producto
	de los elementos $h_1, \ldots, h_m$ en su diagonal. Entonces $h_j \mid \det(H)$ para todo $j \in
	\lbrace 1, \ldots m \rbrace$ y una condición necesaria para la no vacuidad de $F$ es
	\begin{equation*}
		\lcm{h_1, \ldots, h_m} \mid \gcd{k\vec{a}_1^T\vec{\omega} - b_1, \ldots, k\vec{a}_m^T\vec{\omega} - b_m}.
	\end{equation*}
\end{observation}

Si $F$ es vacío, deducimos que este subproblema es infactible y por lo tanto
(\ref{formulation:lattice}) también lo es. Supongamos, pues, que $F \neq \emptyset$. No es difícil
observar que $F$ tiene un elemento maximal $k^*$ y que este elemento es la solución al subproblema
(\ref{subformulation:lattice}). Luego, dada esta solución $k^* \in \Z$, buscamos resolver el
subproblema de factibilidad
\begin{subequations}
	\label{subformulation:feasibility}
	\begin{align}
		M\vec{t} &= \tilde{\vec{y}}, \\
		M\vec{t} &\geq -k^*\vec{\omega}.
	\end{align}
\end{subequations}
Observemos que tenemos un sistema de $n$ ecuaciones lineales con $2n - m - 1$ incógnitas, por lo que
tendremos que lidiar con $n - m - 1$ parámetros libres:
\begin{align}
	\label{eq:feasibility-eqs}
	M\vec{t} = \tilde{\vec{y}} &= U_m\tilde{\vec{y}}_m + U_{n-m}\tilde{\vec{y}}_{n-m} \nonumber \\
   \iff [M, -U_{n-m}] \begin{pmatrix} \vec{t} \\ \tilde{\vec{y}}_{n-m} \end{pmatrix} &= U_m\tilde{\vec{y}}_m.
\end{align}
Si consideramos ahora la forma normal de Smith de esta matriz por bloques, obtenemos dos matrices
unimodulares $S \in \Z^{n \times n}$ y $T \in \Z^{(2n - m - 1) \times (2n - m -1)}$ que satisfacen
\begin{equation*}
	S[M, -U_{n-m}]T = D \in \Z^{n \times (2n - m - 1)},
\end{equation*}
donde $D$ es una matriz diagonal cuyas $n$ primeras entradas son distintas de cero y las restantes
$n - m - 1$ son cero. Si multiplicamos $S$ por la izquierda en ambos lados de la ecuación
(\ref{eq:feasibility-eqs}), tenemos
\begin{equation*}
	D\inv{T}\begin{pmatrix} \vec{t} \\ \tilde{\vec{y}}_{n-m} \end{pmatrix}
	= SU_m\tilde{\vec{y}}_{m}.
\end{equation*}
Si $d_i$ no divide a $(SU_m\tilde{\vec{y}}_{m})_i$ para alguna $i \in \lbrace 1, \ldots, n \rbrace$,
encontramos que la primera ecuación del subproblema (\ref{subformulation:feasibility}) no tiene
solución en los enteros, lo que implica que la elección de $k^*$ fue la incorrecta para asegurar
soluciones enteras a este subproblema. De ser este el caso, redefinimos $F \leftarrow F \setminus
\lbrace k^* \rbrace$. Si $F$ ahora es vacío, entonces (\ref{formulation:lattice}) es
infactible, de caso contrario escogemos el nuevo elemento de maximal de $F$ y repetimos el proceso.

Supongamos, pues que $d_i \mid (SU_m\tilde{\vec{y}}_{m})_i$ para todo $i \in \lbrace 1, \ldots,
n\rbrace$, por lo que obtenemos $n$ soluciones enteras $\vec{r} \coloneq (\vec{r}_1, \ldots,
\vec{r}_n)$ y $n - m - 1$ parámetros libres $\vec{s} \coloneq (\vec{s}_1, \ldots, \vec{s}_{n-m-1})$:
\begin{equation*}
	\inv{T}\begin{pmatrix} \vec{t} \\ \tilde{\vec{y}}_{n-m} \end{pmatrix}
	=
	\begin{pmatrix} \vec{r} \\ \vec{s} \end{pmatrix}.
\end{equation*}
Por lo tanto, nuestro vector $\vec{t}$ es una función lineal de $\vec{s}$, es decir, $\vec{t} =
\vec{t}(\vec{s})$. Hasta este punto el proceso no ha sido complicado, pues nos hemos encargado de
resolver sistemas de ecuaciones lineales diofantinas. En términos del problema original
(\ref{formulation:multiple}), hemos encontrado los vectores $\vec{x}(\vec{s}) \coloneq
k^*\vec{\omega} + M\vec{t}(\vec{s})$ que maximizan la utilidad y que satisfacen todas las
restricciones excepto, posiblemente, las de no negatividad.

La dificultad entra en juego cuando queremos determinar el vector de parámetros $\vec{s} \in
\Z^{n-m-1}$ que hagan que $\vec{t}(\vec{s})$ satisfaga la desigualdad en el subproblema
(\ref{subformulation:feasibility}). Debilitando más esta condición, nos gustaría determinar si el
conjunto
\begin{equation*}
	\lbrace \vec{s} \in \Z^{n-m-1} \vcentcolon M\vec{t} \geq -k^*\vec{\omega} \rbrace
\end{equation*}
es vacío o no. En esta versión debilitada no nos interesa saber qué elementos contiene o tan
siquiera cuántos elementos contiene. Es sabido que los programas enteros tales como
(\ref{formulation:multiple}) o (\ref{formulation:lattice}) son problemas difíciles de resolver, en
el sentido de que no es conocido si se pueden resolver en tiempo polinomial. A lo largo de este
capítulo, no obstante, hemos resuelto todos los problemas en tiempo polinomial\footnote{En
	\cite{alex} se muestra que calcular el máximo común divisor, resolver ecuaciones lineales
	diofantinas, y las factorizaciones tanto de Hermite como de Smith son operaciones acotadas por tiempo
polinomial.}. La única deducción posible, entonces, es que el problema de encontrar los parámetros
$\vec{s}$, o bien de determinar cuántos hay, o bien de determinar su existencia, son todos problemas
difíciles de resolver.

A pesar de lo anterior, hay dos casos donde la dificultad se reduce drásticamente. El caso menos
interesante es cuando $m = n - 1$, de manera que no hay parámetros libres. Esto se debe a que el
politopo factible resultante es un semirrayo o un segmento de línea. Al momento de escoger la
$k^*$-ésima capa entera, estamos agregando la ecuación $k^* = k$, con lo que obtenemos un sistema
lineal entero de $n$ ecuaciones con $n$ incógnitas, y entonces la solución es única. Basta entonces
verificar que este único vector $\vec{t}$ satisface la desigualdad en el subproblema
(\ref{subformulation:feasibility}). El caso un poco más interesante se obtiene cuando $m = n - 2$.
De esta manera obtenemos un solo parámetro, con lo que podemos determinar rápidamente la existencia
o inexistencia de un intervalo de factibilidad.

\begin{example}
	\label{ex:two-var}
	Consideremos el problema con $n = 2$ variables y $m = 1$ restricciones
	\begin{align*}
		\max
			~& x - y, \\
		\text{s.a.} \quad
			& x - y \leq 12 \\
			& 3x + 5y = 25 \\
			& x, y \geq 0.
	\end{align*}
	En este caso tenemos $A = (3, 5), \vec{b} = 25$, y también $\vec{q} = (1, -1)^T$, al igual que
	$\eta = 12$. De (\ref{eq:vec-omega}) y (\ref{eq:mat-T}) obtenemos
	\begin{equation*}
		\vec{\omega} = \begin{pmatrix} 1 \\ 0 \end{pmatrix},
		M = \begin{pmatrix} -1 \\ -1 \end{pmatrix}.
	\end{equation*}
	De la forma normal de Hermite de $A$ tenemos
	\begin{equation*}
		H = 1, U = \begin{pmatrix} 2 & -5 \\ -1 & 3 \end{pmatrix},
	\end{equation*}
	y de la forma normal de Smith de $[M, -U_m]$,
	\begin{equation*}
		S = \begin{pmatrix} 1 & 0 \\ 1 & -1 \end{pmatrix},
		D = \begin{pmatrix} 1 & 0 \\ 0 & 8 \end{pmatrix},
		T = \begin{pmatrix} -1 & 5 \\ 0 & 1 \end{pmatrix}. 
	\end{equation*}

	Como $H = 1$, se sigue que $\inv{H} (\vec{b} - kA\vec{\omega}) = 25 - 3k$ es entero para todo $k
	\in \Z$. Así, el conjunto factible $F$ (c.f. \ref{eq:feas-set}) está dado por
	\begin{equation*}
		F = \Z \cap \lbrace k \in \Z \vcentcolon k \leq 12 \rbrace
		= \lbrace k \in \Z \vcentcolon k \leq \eta = 12 \rbrace.
	\end{equation*}
	Entonces escogemos $k^* = 12$ por ser el elemento maximal de $F$. Así, encontramos
	\begin{equation*}
		SU_m\tilde{\vec{y}}_m = SU_m \left(\inv{H} (\vec{b} - k^*A\vec{\omega})\right)
		= \begin{pmatrix} -22 \\ -33 \end{pmatrix}
	\end{equation*}
	Observemos que la segunda entrada de $SU_m\tilde{\vec{y}}_m$ no es divisible por $D_{22} = 8$.
	Así, el subproblema (\ref{subformulation:feasibility}) no es factible para la elección de $k^*$
	previa. Escogemos el segundo elemento de $F$ más grande, con lo que tenemos $k^* \leftarrow 11$.
	En este caso obtenemos $SU_m\tilde{\vec{y}}_m = (-16, -24)^T$, por lo que sí hay soluciones
	enteras. Luego, se debe satisfacer,
	\begin{equation*}
		\inv{T} \begin{pmatrix} \vec{t} \\ \tilde{\vec{y}}_{n-m} \end{pmatrix} =
		\begin{pmatrix} -16 \\ -24 \end{pmatrix},
	\end{equation*}
	de donde se sigue que $(\vec{t}, \tilde{\vec{y}}_{n-m}) = (1, -3)$. Verificamos factibilidad:
	\begin{equation*}
		M\vec{t} + k^*\vec{\omega}
		= 1 \begin{pmatrix} -1 \\ -1 \end{pmatrix} + 11 \begin{pmatrix} 1 \\ 0 \end{pmatrix}
		= \begin{pmatrix} 10 \\ -1 \end{pmatrix} \not \geq \vec{0}.
	\end{equation*}
	Ahora la elección de $k^*$ dio un punto entero pero con una entrada negativa. Seguimos este
	procedimiento hasta llegar a $k^* \leftarrow 3$. En este caso obtenemos $(\vec{t},
	\tilde{\vec{y}}_{n-m}) = (-2, 6)^T$, de donde
	\begin{equation*}
		M\vec{t} + k^*\vec{\omega}
		= -2 \begin{pmatrix} -1 \\ -1 \end{pmatrix} + 3 \begin{pmatrix} 1 \\ 0 \end{pmatrix}
		= \begin{pmatrix} 5 \\ 2 \end{pmatrix} \geq \vec{0}.
	\end{equation*}
	Concluimos diciendo que $(k^*, \vec{t}) \coloneq (3, -2)$ es el óptimo del programa
	(\ref{formulation:lattice}) y entonces $(x, y) = (5, 2)$ es el óptimo de
	(\ref{formulation:multiple}).
\end{example}
\begin{example}
	Ahora consideremos el problema con $n = 3$ variables y $m = 1$ restricciones
	\begin{align*}
		\max
			~& x - y + 2z, \\
		\text{s.a.} \quad
			& x - y  + 2z \leq 10 \\
			& 3x + 4y - z = 15 \\
			& x, y, z \geq 0.
	\end{align*}
	En este caso tenemos $A = (3, 4, -1), \vec{b} = 15$, y también $\vec{q} = (1, -1, 2)^T$, al igual que
	$\eta = 10$. De (\ref{eq:vec-omega}) y (\ref{eq:mat-T}) obtenemos
	\begin{equation*}
		\vec{\omega} = \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix},
		M = \begin{pmatrix} -1 & 0 \\ 1 & 2 \\ 0 & 1 \end{pmatrix}.
	\end{equation*}
	De la forma normal de Hermite de $A$ tenemos
	\begin{equation*}
		H = 1, U = \begin{pmatrix} 0 & 0 & 1 \\ 1 & 0 & 0 \\ -1 & 4 & 3 \end{pmatrix},
	\end{equation*}
	y de la forma normal de Smith de $[M, -U_m]$,
	\begin{equation*}
		S = \begin{pmatrix}
			1 & 0 & 0 \\
			1 & -1 & 0 \\
			-4 & 4 & -1
		\end{pmatrix},
		D = \begin{pmatrix}
			1 & 0 & 0 & 0 \\
			0 & 1 & 0 & 0 \\
			0 & 0 & 7 & 0
		\end{pmatrix},
		T = \begin{pmatrix}
			1 & 0 & 0 & 1 \\
			0 & 0 & 1 & -1 \\
			0 & 1 & 2 & -1 \\
			0 & 0 & 0 & 1
		\end{pmatrix}.
	\end{equation*}
	Nuevamente, observemos que $H = 1$ y por lo tanto $F = \lbrace k \in \Z \vcentcolon k \leq 10
	\rbrace$. Seguimos exactamente el mismo procedimiento que en el Ejemplo \ref{ex:two-var} hasta
	llegar a $k^* \leftarrow 5$. Encontramos que se satisface
	\begin{equation*}
		\inv{T} \begin{pmatrix} \vec{t} \\ \tilde{\vec{y}}_{n-m} \end{pmatrix}
		=
		\begin{pmatrix} 0 \\ 0 \\ 0 \\ s \end{pmatrix}
		\implies
		\begin{pmatrix} \vec{t} \\ \tilde{\vec{y}}_{n-m} \end{pmatrix}
		=
		s \begin{pmatrix} 1 \\ -1 \\ -1 \\ 1 \end{pmatrix},
	\end{equation*}
	donde $s \in \Z$ es la única variable libre. En este caso podemos determinar rápidamente un
	intervalo de existencia: tenemos $M\vec{t} \geq -k^*\vec{\omega}$ si y solo si
	\begin{equation*}
		s\begin{pmatrix} 1 \\ -1 \\ -1 \end{pmatrix} \geq
		\begin{pmatrix} -5 \\ 0 \\ 0 \end{pmatrix},
	\end{equation*}
	de donde se sigue inmediatamente que $s \in \lbrace -5, -4, \ldots, 0 \rbrace$. Sustituyendo en
	$\vec{t}$ y transformando a $\vec{x}$, encontramos que
	\begin{equation*}
		\left\lbrace
			\begin{pmatrix} 0 \\ 5 \\ 5 \end{pmatrix},
			\begin{pmatrix} 1 \\ 4 \\ 4 \end{pmatrix},
			\begin{pmatrix} 2 \\ 3 \\ 3 \end{pmatrix},
			\begin{pmatrix} 3 \\ 2 \\ 2 \end{pmatrix},
			\begin{pmatrix} 4 \\ 1 \\ 1 \end{pmatrix},
			\begin{pmatrix} 5 \\ 0 \\ 0 \end{pmatrix}
		\right\rbrace
	\end{equation*}
	son las seis soluciones del problema. Todas alcanzan un nivel de utilidad $k^* = 5$.
\end{example}

\section{Análisis de resultados}
\noindent
Una consecuencia del Teorema \ref{infinite:th:complexity} es que la complejidad algoritmítica del
problema (\ref{theory:formulation}) es lineal en la dimensión $n$ siempre y cuando $\vec{q}_i < 0$
para alguna $i \in \lbrace 2, \ldots, n\rbrace$. En esta sección describimos un algoritmo cuyo
tiempo de terminación es $\mathcal{O}(n)$. A través de los resultados obtenidos previamente, somos
capaces de mostrar que nuestro algoritmo es correcto. Finalmente, implementamos nuestro algoritmo en
el lenguaje de programación Python y comparamos sus tiempos de terminación con los de la
implementación de Ramificación y Acotamiento en la librería PuLP. 
